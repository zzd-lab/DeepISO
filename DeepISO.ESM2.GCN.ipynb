{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_41505/602101333.py:42: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/torch/csrc/utils/tensor_new.cpp:245.)\n",
      "  protein_tensor = torch.tensor(protein_data, dtype=torch.float32).squeeze()\n"
     ]
    }
   ],
   "source": [
    "#Data preparation\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from Bio.PDB import *\n",
    "from Bio.PDB.DSSP import DSSP\n",
    "\n",
    "class ProteinDataProcessor:\n",
    "    def __init__(self, pesto_file_path, pdb_directory):\n",
    "        self.pesto_file_path = pesto_file_path\n",
    "        self.pdb_directory = pdb_directory\n",
    "        self.pesto_dict = {}\n",
    "        self.secondary_dict = {}\n",
    "        self.ss_mapping = {'H': 0, 'G': 0, 'I': 0, 'E': 1, 'T': 2, 'B': 2, 'S': 2, '-': 3}\n",
    "\n",
    "    def read_pesto_file(self):\n",
    "        with open(self.pesto_file_path, 'r') as file:\n",
    "            for line in file:\n",
    "                columns = line.strip().split('\\t')\n",
    "                protein_name = columns[0]\n",
    "                data_values = [float(value) for value in columns[1:] if value != '0']  \n",
    "                self.pesto_dict[protein_name] = data_values\n",
    "\n",
    "    def process_secondary_structure(self):\n",
    "        for pdb_filename in os.listdir(self.pdb_directory):\n",
    "            pdb_filepath = os.path.join(self.pdb_directory, pdb_filename)\n",
    "            parser = PDBParser(QUIET=True)\n",
    "            structure = parser.get_structure(\"protein\", pdb_filepath)\n",
    "            model = structure[0]\n",
    "            dssp = DSSP(model, pdb_filepath)\n",
    "            protein_data = []\n",
    "\n",
    "            for residue in dssp:\n",
    "                res_id = residue[1]\n",
    "                ss = residue[2]\n",
    "                code = self.ss_mapping[ss]\n",
    "                codes = [code]  \n",
    "                #one-hot encoding\n",
    "                one_hot_codes = np.eye(4)[codes]  \n",
    "                protein_data.append(one_hot_codes)\n",
    "\n",
    "            protein_tensor = torch.tensor(protein_data, dtype=torch.float32).squeeze()\n",
    "            protein_name = os.path.splitext(pdb_filename)[0]\n",
    "            self.secondary_dict[protein_name] = protein_tensor\n",
    "\n",
    "    def prepare_data(self):\n",
    "        self.read_pesto_file()\n",
    "        self.process_secondary_structure()\n",
    "        return self.pesto_dict, self.secondary_dict\n",
    "\n",
    "file_path = \"/mnt/disk1/guoxiaokun/isoform/PeSTO/PeSTo-main/geometirc.allfeature.txt\"\n",
    "pdb_directory = \"/mnt/disk1/guoxiaokun/isoform/double.GCN/PDB\"\n",
    "\n",
    "processor = ProteinDataProcessor(file_path, pdb_directory)\n",
    "pesto_dict, secondary_dict = processor.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xkguo/miniconda3/envs/pytorch2.0/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A2BP1: torch.Size([397, 1284])\n",
      "ABCF3_1: torch.Size([709, 1284])\n",
      "ABCF3_2: torch.Size([319, 1284])\n",
      "ABI2: torch.Size([513, 1284])\n",
      "ABLIM2: torch.Size([611, 1284])\n",
      "ACBD4_1: torch.Size([341, 1284])\n",
      "ACBD4_2: torch.Size([306, 1284])\n",
      "ACBD4_3: torch.Size([305, 1284])\n",
      "ACBD4_4: torch.Size([269, 1284])\n",
      "ACMSD_3: torch.Size([189, 1284])\n",
      "ACTN1: torch.Size([892, 1284])\n",
      "ACTN2: torch.Size([894, 1284])\n",
      "ACTN4_1: torch.Size([911, 1284])\n",
      "ACTN4_4: torch.Size([75, 1284])\n",
      "ACY3: torch.Size([319, 1284])\n",
      "ADAMTSL4: torch.Size([1074, 1284])\n",
      "AES: torch.Size([197, 1284])\n",
      "AGTRAP: torch.Size([159, 1284])\n",
      "AHCYL1: torch.Size([530, 1284])\n",
      "AIMP2: torch.Size([320, 1284])\n",
      "AKAP10_1: torch.Size([662, 1284])\n",
      "AKAP10_3: torch.Size([601, 1284])\n",
      "AKAP10_4: torch.Size([58, 1284])\n",
      "AKAP10_5: torch.Size([96, 1284])\n",
      "AKT1_1: torch.Size([480, 1284])\n",
      "AKT1_2: torch.Size([181, 1284])\n",
      "ALS2CR12: torch.Size([445, 1284])\n",
      "AMMECR1_1: torch.Size([296, 1284])\n",
      "AMMECR1_2: torch.Size([333, 1284])\n",
      "AMOTL2: torch.Size([779, 1284])\n",
      "ANKMY1_2: torch.Size([218, 1284])\n",
      "ANKRD50_1: torch.Size([743, 1284])\n",
      "ANKRD50_2: torch.Size([160, 1284])\n",
      "AP3B1_1: torch.Size([1094, 1284])\n",
      "AP3B1_2: torch.Size([860, 1284])\n",
      "AP3B1_3: torch.Size([70, 1284])\n",
      "APBB1IP: torch.Size([666, 1284])\n",
      "ARHGAP26_1: torch.Size([759, 1284])\n",
      "ARHGAP26_2: torch.Size([681, 1284])\n",
      "ARHGEF15_1: torch.Size([841, 1284])\n",
      "ARHGEF15_2: torch.Size([790, 1284])\n",
      "ARL6IP1: torch.Size([203, 1284])\n",
      "ARMC1: torch.Size([282, 1284])\n",
      "ARRB1: torch.Size([418, 1284])\n",
      "ARSA_1: torch.Size([507, 1284])\n",
      "ASAP3: torch.Size([903, 1284])\n",
      "ASL: torch.Size([464, 1284])\n",
      "ATCAY_2: torch.Size([359, 1284])\n",
      "ATF4: torch.Size([351, 1284])\n",
      "AXIN1_1: torch.Size([826, 1284])\n",
      "AXIN1_2: torch.Size([862, 1284])\n",
      "AXIN1_3: torch.Size([779, 1284])\n",
      "BAD: torch.Size([168, 1284])\n",
      "BAG1_1: torch.Size([274, 1284])\n",
      "BAG1_2: torch.Size([204, 1284])\n",
      "BANP_1: torch.Size([469, 1284])\n",
      "BANP_2: torch.Size([128, 1284])\n",
      "BANP_3: torch.Size([356, 1284])\n",
      "BANP_4: torch.Size([508, 1284])\n",
      "BANP_5: torch.Size([505, 1284])\n",
      "BANP_7: torch.Size([488, 1284])\n",
      "BANP: torch.Size([519, 1284])\n",
      "BBS4_1: torch.Size([519, 1284])\n",
      "BBS4_3: torch.Size([290, 1284])\n",
      "BCL2L1_1: torch.Size([233, 1284])\n",
      "BCL2L1_2: torch.Size([170, 1284])\n",
      "BCL2L1_3: torch.Size([151, 1284])\n",
      "BCL2L13: torch.Size([485, 1284])\n",
      "BEND5: torch.Size([421, 1284])\n",
      "BEND7: torch.Size([519, 1284])\n",
      "BHLHE40: torch.Size([412, 1284])\n",
      "BIK: torch.Size([160, 1284])\n",
      "BLZF1: torch.Size([400, 1284])\n",
      "BMF: torch.Size([184, 1284])\n",
      "BTC_1: torch.Size([178, 1284])\n",
      "BTC_2: torch.Size([129, 1284])\n",
      "BTRC_1: torch.Size([605, 1284])\n",
      "BTRC_2: torch.Size([118, 1284])\n",
      "BTRC_3: torch.Size([636, 1284])\n",
      "BTRC_4: torch.Size([579, 1284])\n",
      "C10orf18: torch.Size([2430, 1284])\n",
      "C10orf96: torch.Size([258, 1284])\n",
      "C12orf10: torch.Size([376, 1284])\n",
      "C15orf55: torch.Size([1132, 1284])\n",
      "C19orf46: torch.Size([404, 1284])\n",
      "C1orf94: torch.Size([598, 1284])\n",
      "C6orf142_1: torch.Size([234, 1284])\n",
      "C6orf142_2: torch.Size([400, 1284])\n",
      "C6orf142_6: torch.Size([308, 1284])\n",
      "CA9_1: torch.Size([459, 1284])\n",
      "CA9_2: torch.Size([284, 1284])\n",
      "CADPS: torch.Size([1353, 1284])\n",
      "CALCOCO2: torch.Size([446, 1284])\n",
      "CAMK2B: torch.Size([666, 1284])\n",
      "CAMK2D: torch.Size([499, 1284])\n",
      "CAPN3_1: torch.Size([309, 1284])\n",
      "CAPN3_2: torch.Size([83, 1284])\n",
      "CAPN3_7: torch.Size([265, 1284])\n",
      "CARD9: torch.Size([536, 1284])\n",
      "CASP2_1: torch.Size([452, 1284])\n",
      "CASP2_2: torch.Size([81, 1284])\n",
      "CASP2: torch.Size([452, 1284])\n",
      "CBLB: torch.Size([982, 1284])\n",
      "CBLL1: torch.Size([491, 1284])\n",
      "CCDC114: torch.Size([670, 1284])\n",
      "CCDC136: torch.Size([1154, 1284])\n",
      "CCDC33: torch.Size([958, 1284])\n",
      "CCDC36: torch.Size([594, 1284])\n",
      "CCDC53: torch.Size([194, 1284])\n",
      "CCDC57: torch.Size([915, 1284])\n",
      "CCDC67: torch.Size([604, 1284])\n",
      "CCDC99: torch.Size([605, 1284])\n",
      "CCND2: torch.Size([289, 1284])\n",
      "CCNDBP1: torch.Size([360, 1284])\n",
      "CD99L2_1: torch.Size([262, 1284])\n",
      "CD99L2_3: torch.Size([119, 1284])\n",
      "CDC23: torch.Size([597, 1284])\n",
      "CDC42EP2: torch.Size([210, 1284])\n",
      "CDCA7L: torch.Size([454, 1284])\n",
      "CDK20_1: torch.Size([275, 1284])\n",
      "CDK20_3: torch.Size([305, 1284])\n",
      "CDK20_4: torch.Size([284, 1284])\n",
      "CDK20_5: torch.Size([229, 1284])\n",
      "CDK5_1: torch.Size([292, 1284])\n",
      "CDK5_2: torch.Size([260, 1284])\n",
      "CDR2: torch.Size([454, 1284])\n",
      "CDX4: torch.Size([284, 1284])\n",
      "CEP55: torch.Size([464, 1284])\n",
      "CEP57L1: torch.Size([460, 1284])\n",
      "CEP63: torch.Size([703, 1284])\n",
      "CEP70: torch.Size([597, 1284])\n",
      "CEP72: torch.Size([647, 1284])\n",
      "CEP76: torch.Size([659, 1284])\n",
      "CFP_1: torch.Size([469, 1284])\n",
      "CFP_2: torch.Size([242, 1284])\n",
      "CLCN2_1: torch.Size([387, 1284])\n",
      "CLCN2_2: torch.Size([422, 1284])\n",
      "CLCN2_3: torch.Size([420, 1284])\n",
      "CLCN2_4: torch.Size([398, 1284])\n",
      "CLCN2_5: torch.Size([85, 1284])\n",
      "CLINT1_1: torch.Size([625, 1284])\n",
      "CLK2: torch.Size([499, 1284])\n",
      "CMTM5: torch.Size([223, 1284])\n",
      "COG5: torch.Size([839, 1284])\n",
      "COG7_1: torch.Size([770, 1284])\n",
      "COG7_3: torch.Size([176, 1284])\n",
      "COG8: torch.Size([612, 1284])\n",
      "COL1A2_1: torch.Size([1366, 1284])\n",
      "COL1A2_5: torch.Size([486, 1284])\n",
      "COPS4_1: torch.Size([406, 1284])\n",
      "COPS4_2: torch.Size([420, 1284])\n",
      "CPSF7: torch.Size([471, 1284])\n",
      "CREB3L1: torch.Size([519, 1284])\n",
      "CRK_1: torch.Size([304, 1284])\n",
      "CRK_2: torch.Size([204, 1284])\n",
      "CRLF3: torch.Size([442, 1284])\n",
      "CRX: torch.Size([299, 1284])\n",
      "CSGALNACT2_1: torch.Size([542, 1284])\n",
      "CSGALNACT2_2: torch.Size([416, 1284])\n",
      "CSGALNACT2_3: torch.Size([342, 1284])\n",
      "CTBP1: torch.Size([440, 1284])\n",
      "CTBP2: torch.Size([445, 1284])\n",
      "CXCR3_1: torch.Size([368, 1284])\n",
      "CXCR3_2: torch.Size([255, 1284])\n",
      "CXorf41: torch.Size([214, 1284])\n",
      "DCTN4_1: torch.Size([460, 1284])\n",
      "DCTN4_2: torch.Size([441, 1284])\n",
      "DCTN4_3: torch.Size([50, 1284])\n",
      "DDX17: torch.Size([729, 1284])\n",
      "DDX39A: torch.Size([427, 1284])\n",
      "DDX39B: torch.Size([428, 1284])\n",
      "DES: torch.Size([470, 1284])\n",
      "DGUOK_1: torch.Size([277, 1284])\n",
      "DGUOK_2: torch.Size([89, 1284])\n",
      "DGUOK_5: torch.Size([53, 1284])\n",
      "DHX15: torch.Size([795, 1284])\n",
      "DIABLO_1: torch.Size([239, 1284])\n",
      "DIABLO_2: torch.Size([195, 1284])\n",
      "DLX3: torch.Size([287, 1284])\n",
      "DMRTB1_2: torch.Size([102, 1284])\n",
      "DOCK8: torch.Size([2099, 1284])\n",
      "DOLK_1: torch.Size([538, 1284])\n",
      "DOLK_2: torch.Size([106, 1284])\n",
      "DPPA4: torch.Size([304, 1284])\n",
      "DTNBP1: torch.Size([351, 1284])\n",
      "DYDC1: torch.Size([177, 1284])\n",
      "DYX1C1_1: torch.Size([381, 1284])\n",
      "DYX1C1_2: torch.Size([255, 1284])\n",
      "DYX1C1_3: torch.Size([188, 1284])\n",
      "E2F6_1: torch.Size([281, 1284])\n",
      "E2F6_3: torch.Size([38, 1284])\n",
      "EFCAB4A: torch.Size([399, 1284])\n",
      "EFEMP1_1: torch.Size([493, 1284])\n",
      "EFEMP1_2: torch.Size([413, 1284])\n",
      "EFEMP2: torch.Size([443, 1284])\n",
      "EFHA1_1: torch.Size([434, 1284])\n",
      "EFHA1_2: torch.Size([124, 1284])\n",
      "EFHC2: torch.Size([749, 1284])\n",
      "EFS: torch.Size([561, 1284])\n",
      "EGR2_3: torch.Size([201, 1284])\n",
      "EHMT2: torch.Size([1210, 1284])\n",
      "EID1: torch.Size([187, 1284])\n",
      "ELK3: torch.Size([407, 1284])\n",
      "EMILIN1: torch.Size([1016, 1284])\n",
      "ERCC8_1: torch.Size([205, 1284])\n",
      "ERCC8_3: torch.Size([98, 1284])\n",
      "ETV6_2: torch.Size([338, 1284])\n",
      "ETV6: torch.Size([452, 1284])\n",
      "EXOC5: torch.Size([708, 1284])\n",
      "EXOSC8: torch.Size([276, 1284])\n",
      "FAM126A_1: torch.Size([521, 1284])\n",
      "FAM126A_2: torch.Size([419, 1284])\n",
      "FAM126A_3: torch.Size([406, 1284])\n",
      "FAM131C: torch.Size([280, 1284])\n",
      "FAM154A: torch.Size([474, 1284])\n",
      "FAM168A: torch.Size([244, 1284])\n",
      "FAM22F: torch.Size([756, 1284])\n",
      "FAM54B_1: torch.Size([292, 1284])\n",
      "FAM54B_2: torch.Size([31, 1284])\n",
      "FAM64A_1: torch.Size([248, 1284])\n",
      "FAM64A_2: torch.Size([238, 1284])\n",
      "FAM9B: torch.Size([186, 1284])\n",
      "FANCC_1: torch.Size([558, 1284])\n",
      "FANCC_2: torch.Size([119, 1284])\n",
      "FANCG_1: torch.Size([622, 1284])\n",
      "FANCG_2: torch.Size([616, 1284])\n",
      "FANCG_3: torch.Size([551, 1284])\n",
      "FANCG_5: torch.Size([409, 1284])\n",
      "FANCG_6: torch.Size([48, 1284])\n",
      "FASLG: torch.Size([281, 1284])\n",
      "FATE1: torch.Size([183, 1284])\n",
      "FBXO8_1: torch.Size([319, 1284])\n",
      "FBXO8_2: torch.Size([207, 1284])\n",
      "FCHO1: torch.Size([889, 1284])\n",
      "FCHSD2: torch.Size([740, 1284])\n",
      "FGA_1: torch.Size([218, 1284])\n",
      "FGA_2: torch.Size([436, 1284])\n",
      "FGA_5: torch.Size([133, 1284])\n",
      "FGA_8: torch.Size([84, 1284])\n",
      "FH_1: torch.Size([510, 1284])\n",
      "FH_5: torch.Size([165, 1284])\n",
      "FH_7: torch.Size([137, 1284])\n",
      "FHL2: torch.Size([279, 1284])\n",
      "FHL3: torch.Size([280, 1284])\n",
      "FHL5: torch.Size([284, 1284])\n",
      "FOXM1: torch.Size([763, 1284])\n",
      "FXR2: torch.Size([673, 1284])\n",
      "GAD1_1: torch.Size([594, 1284])\n",
      "GAD1_2: torch.Size([111, 1284])\n",
      "GAD1_3: torch.Size([77, 1284])\n",
      "GALT_1: torch.Size([379, 1284])\n",
      "GALT_2: torch.Size([193, 1284])\n",
      "GATA3: torch.Size([443, 1284])\n",
      "GDPD5: torch.Size([605, 1284])\n",
      "GFAP: torch.Size([432, 1284])\n",
      "GINS3_1: torch.Size([216, 1284])\n",
      "GINS3_2: torch.Size([255, 1284])\n",
      "GKAP1: torch.Size([366, 1284])\n",
      "GLRX3: torch.Size([335, 1284])\n",
      "GMCL1: torch.Size([515, 1284])\n",
      "GMPPA: torch.Size([420, 1284])\n",
      "GNMT_1: torch.Size([295, 1284])\n",
      "GNMT_3: torch.Size([276, 1284])\n",
      "GNMT_4: torch.Size([151, 1284])\n",
      "GNMT: torch.Size([295, 1284])\n",
      "GOLGA2: torch.Size([1002, 1284])\n",
      "GOPC: torch.Size([462, 1284])\n",
      "GORASP1: torch.Size([440, 1284])\n",
      "GPRASP2: torch.Size([838, 1284])\n",
      "GRAMD3: torch.Size([432, 1284])\n",
      "GSS_1: torch.Size([474, 1284])\n",
      "GSS: torch.Size([474, 1284])\n",
      "HGS_1: torch.Size([777, 1284])\n",
      "HGS_2: torch.Size([699, 1284])\n",
      "HGS: torch.Size([777, 1284])\n",
      "HMBOX1: torch.Size([420, 1284])\n",
      "HMG20A: torch.Size([347, 1284])\n",
      "HNRNPK: torch.Size([463, 1284])\n",
      "HNRPLL_1: torch.Size([542, 1284])\n",
      "HNRPLL_2: torch.Size([573, 1284])\n",
      "HNRPLL_3: torch.Size([282, 1284])\n",
      "HOMER3: torch.Size([361, 1284])\n",
      "HOMEZ: torch.Size([550, 1284])\n",
      "HOOK2: torch.Size([719, 1284])\n",
      "HSFY1: torch.Size([401, 1284])\n",
      "HSPA8: torch.Size([646, 1284])\n",
      "HSPD1_1: torch.Size([573, 1284])\n",
      "HSPD1_2: torch.Size([56, 1284])\n",
      "HSPD1_4: torch.Size([169, 1284])\n",
      "IKZF1: torch.Size([519, 1284])\n",
      "IKZF3: torch.Size([509, 1284])\n",
      "INPP1_1: torch.Size([399, 1284])\n",
      "INPP1_2: torch.Size([105, 1284])\n",
      "INTS4: torch.Size([963, 1284])\n",
      "IRAK4_1: torch.Size([460, 1284])\n",
      "IRAK4_2: torch.Size([60, 1284])\n",
      "IVD_1: torch.Size([423, 1284])\n",
      "IVD_2: torch.Size([393, 1284])\n",
      "IVD_3: torch.Size([88, 1284])\n",
      "JMJD5_1: torch.Size([416, 1284])\n",
      "JMJD5_2: torch.Size([385, 1284])\n",
      "JMJD5_3: torch.Size([301, 1284])\n",
      "JUP: torch.Size([745, 1284])\n",
      "KCNA3: torch.Size([575, 1284])\n",
      "KCNIP4: torch.Size([250, 1284])\n",
      "KHDRBS2: torch.Size([349, 1284])\n",
      "KHDRBS3: torch.Size([346, 1284])\n",
      "KIAA0753: torch.Size([967, 1284])\n",
      "KIAA0907_1: torch.Size([241, 1284])\n",
      "KIAA0907_2: torch.Size([174, 1284])\n",
      "KIAA1712: torch.Size([390, 1284])\n",
      "KIF9: torch.Size([790, 1284])\n",
      "KIFAP3: torch.Size([792, 1284])\n",
      "KIFC3: torch.Size([833, 1284])\n",
      "KLC3: torch.Size([504, 1284])\n",
      "KLHL6: torch.Size([621, 1284])\n",
      "KRT13: torch.Size([458, 1284])\n",
      "KRT15: torch.Size([456, 1284])\n",
      "KRT18: torch.Size([430, 1284])\n",
      "KRT19: torch.Size([400, 1284])\n",
      "KRT31: torch.Size([416, 1284])\n",
      "KRT33B: torch.Size([404, 1284])\n",
      "KRT38: torch.Size([456, 1284])\n",
      "KRT40: torch.Size([431, 1284])\n",
      "KRT6A_1: torch.Size([564, 1284])\n",
      "KRT6A_2: torch.Size([96, 1284])\n",
      "KRTAP10-1: torch.Size([282, 1284])\n",
      "KRTAP10-3: torch.Size([221, 1284])\n",
      "KRTAP10-8: torch.Size([259, 1284])\n",
      "KRTAP10-9: torch.Size([292, 1284])\n",
      "KRTAP12-2: torch.Size([146, 1284])\n",
      "KRTAP13-1: torch.Size([172, 1284])\n",
      "KRTAP2-4: torch.Size([128, 1284])\n",
      "KRTAP26-1: torch.Size([210, 1284])\n",
      "KRTAP3-2: torch.Size([98, 1284])\n",
      "KRTAP4-12: torch.Size([201, 1284])\n",
      "KRTAP4-2: torch.Size([136, 1284])\n",
      "KRTAP5-9: torch.Size([169, 1284])\n",
      "L3MBTL2_1: torch.Size([705, 1284])\n",
      "L3MBTL3: torch.Size([780, 1284])\n",
      "LAMB3_1: torch.Size([1172, 1284])\n",
      "LAMB3_2: torch.Size([84, 1284])\n",
      "LAX1: torch.Size([398, 1284])\n",
      "LCK_1: torch.Size([539, 1284])\n",
      "LCK_2: torch.Size([509, 1284])\n",
      "LCK_3: torch.Size([458, 1284])\n",
      "LCP2: torch.Size([533, 1284])\n",
      "LDB3_1: torch.Size([283, 1284])\n",
      "LDB3_2: torch.Size([330, 1284])\n",
      "LDB3_3: torch.Size([111, 1284])\n",
      "LDOC1: torch.Size([146, 1284])\n",
      "LHX4_2: torch.Size([89, 1284])\n",
      "LHX4: torch.Size([390, 1284])\n",
      "LHX8: torch.Size([356, 1284])\n",
      "LMBR1L_1: torch.Size([489, 1284])\n",
      "LMBR1L_2: torch.Size([46, 1284])\n",
      "LMBR1L_3: torch.Size([144, 1284])\n",
      "LMBR1L_4: torch.Size([469, 1284])\n",
      "LMBR1L_5: torch.Size([368, 1284])\n",
      "LOC100288797: torch.Size([195, 1284])\n",
      "LRRIQ3: torch.Size([624, 1284])\n",
      "LSM1_1: torch.Size([133, 1284])\n",
      "LSM1_3: torch.Size([44, 1284])\n",
      "LSM3: torch.Size([102, 1284])\n",
      "LZTS2: torch.Size([669, 1284])\n",
      "MAD1L1: torch.Size([718, 1284])\n",
      "MAGEA11: torch.Size([429, 1284])\n",
      "MAGEA12: torch.Size([314, 1284])\n",
      "MAGEA6: torch.Size([314, 1284])\n",
      "MAGED1: torch.Size([778, 1284])\n",
      "MAL2: torch.Size([176, 1284])\n",
      "MAPK1IP1L: torch.Size([245, 1284])\n",
      "MAPK7: torch.Size([816, 1284])\n",
      "MBIP: torch.Size([344, 1284])\n",
      "MCM7_1: torch.Size([719, 1284])\n",
      "MCM7_2: torch.Size([134, 1284])\n",
      "MCMBP_1: torch.Size([640, 1284])\n",
      "MCMBP_3: torch.Size([195, 1284])\n",
      "MCMBP: torch.Size([642, 1284])\n",
      "MDFI: torch.Size([246, 1284])\n",
      "MDM4: torch.Size([490, 1284])\n",
      "MED21_2: torch.Size([73, 1284])\n",
      "MED7: torch.Size([233, 1284])\n",
      "MEF2A_1: torch.Size([499, 1284])\n",
      "MEF2A_3: torch.Size([505, 1284])\n",
      "MEF2A_4: torch.Size([497, 1284])\n",
      "MEF2A_5: torch.Size([429, 1284])\n",
      "MEOX1: torch.Size([254, 1284])\n",
      "MEOX2: torch.Size([304, 1284])\n",
      "METTL17_1: torch.Size([447, 1284])\n",
      "METTL17_2: torch.Size([158, 1284])\n",
      "METTL17_4: torch.Size([456, 1284])\n",
      "MID2: torch.Size([735, 1284])\n",
      "MIER2: torch.Size([545, 1284])\n",
      "MIF4GD: torch.Size([222, 1284])\n",
      "MIPOL1_1: torch.Size([261, 1284])\n",
      "MIPOL1_2: torch.Size([277, 1284])\n",
      "MIPOL1_4: torch.Size([184, 1284])\n",
      "MIPOL1: torch.Size([442, 1284])\n",
      "MKRN2: torch.Size([416, 1284])\n",
      "MKRN3: torch.Size([507, 1284])\n",
      "MLF1_1: torch.Size([268, 1284])\n",
      "MLF1_5: torch.Size([32, 1284])\n",
      "MNAT1_1: torch.Size([309, 1284])\n",
      "MNAT1_2: torch.Size([128, 1284])\n",
      "MOBP_1: torch.Size([81, 1284])\n",
      "MOBP_2: torch.Size([182, 1284])\n",
      "MPP1: torch.Size([466, 1284])\n",
      "MPV17_1: torch.Size([176, 1284])\n",
      "MPV17_2: torch.Size([99, 1284])\n",
      "MPV17_3: torch.Size([147, 1284])\n",
      "MPV17_4: torch.Size([72, 1284])\n",
      "MTUS2: torch.Size([1369, 1284])\n",
      "MVK_1: torch.Size([396, 1284])\n",
      "MVK_2: torch.Size([344, 1284])\n",
      "MVK: torch.Size([396, 1284])\n",
      "MXI1_1: torch.Size([182, 1284])\n",
      "MXI1_2: torch.Size([43, 1284])\n",
      "MYD88: torch.Size([296, 1284])\n",
      "MYOT_1: torch.Size([498, 1284])\n",
      "MYOT_2: torch.Size([93, 1284])\n",
      "MYOZ2: torch.Size([264, 1284])\n",
      "N6AMT2: torch.Size([214, 1284])\n",
      "NAV2: torch.Size([2488, 1284])\n",
      "NBR1: torch.Size([966, 1284])\n",
      "NCF2_1: torch.Size([526, 1284])\n",
      "NCF2_3: torch.Size([181, 1284])\n",
      "NCK1_1: torch.Size([377, 1284])\n",
      "NCK1_2: torch.Size([170, 1284])\n",
      "NCK1_3: torch.Size([244, 1284])\n",
      "NCK2_1: torch.Size([380, 1284])\n",
      "NCK2_2: torch.Size([83, 1284])\n",
      "NDN_1: torch.Size([321, 1284])\n",
      "NDN_2: torch.Size([255, 1284])\n",
      "NDN_3: torch.Size([85, 1284])\n",
      "NDN_4: torch.Size([97, 1284])\n",
      "NDN_5: torch.Size([160, 1284])\n",
      "NDRG4_1: torch.Size([339, 1284])\n",
      "NDRG4_2: torch.Size([352, 1284])\n",
      "NEBL: torch.Size([1014, 1284])\n",
      "NEFL_1: torch.Size([284, 1284])\n",
      "NEFL_2: torch.Size([377, 1284])\n",
      "NEFL: torch.Size([543, 1284])\n",
      "NFIA: torch.Size([509, 1284])\n",
      "NFIB_2: torch.Size([203, 1284])\n",
      "NFIX: torch.Size([502, 1284])\n",
      "NLGN3_1: torch.Size([828, 1284])\n",
      "NLGN3_2: torch.Size([64, 1284])\n",
      "NME5_1: torch.Size([212, 1284])\n",
      "NME5_3: torch.Size([43, 1284])\n",
      "NMI: torch.Size([307, 1284])\n",
      "NMNAT1: torch.Size([279, 1284])\n",
      "NOTCH2NL: torch.Size([236, 1284])\n",
      "NPM1_1: torch.Size([265, 1284])\n",
      "NPM1_2: torch.Size([294, 1284])\n",
      "NPM2: torch.Size([214, 1284])\n",
      "NR1D1: torch.Size([614, 1284])\n",
      "NR1H3: torch.Size([447, 1284])\n",
      "NR1H4: torch.Size([486, 1284])\n",
      "NRF1: torch.Size([503, 1284])\n",
      "NUP62CL_1: torch.Size([184, 1284])\n",
      "NUP62CL_2: torch.Size([221, 1284])\n",
      "NUP62: torch.Size([522, 1284])\n",
      "OGT: torch.Size([1046, 1284])\n",
      "OPTN_1: torch.Size([577, 1284])\n",
      "OPTN: torch.Size([577, 1284])\n",
      "P4HA3: torch.Size([544, 1284])\n",
      "PAICS: torch.Size([425, 1284])\n",
      "PAK1IP1_1: torch.Size([392, 1284])\n",
      "PAK1IP1_4: torch.Size([30, 1284])\n",
      "PCBD1: torch.Size([104, 1284])\n",
      "PDE4DIP: torch.Size([2346, 1284])\n",
      "PDE9A_1: torch.Size([533, 1284])\n",
      "PDE9A_2: torch.Size([593, 1284])\n",
      "PDE9A_3: torch.Size([465, 1284])\n",
      "PDE9A: torch.Size([593, 1284])\n",
      "PEX5: torch.Size([639, 1284])\n",
      "PGAP2_1: torch.Size([250, 1284])\n",
      "PGAP2_3: torch.Size([56, 1284])\n",
      "PGAP2_4: torch.Size([254, 1284])\n",
      "PGBD1: torch.Size([809, 1284])\n",
      "PHF21B_1: torch.Size([531, 1284])\n",
      "PHF21B_2: torch.Size([489, 1284])\n",
      "PHF21B_3: torch.Size([302, 1284])\n",
      "PLK4: torch.Size([970, 1284])\n",
      "PLP1_1: torch.Size([242, 1284])\n",
      "PLP1_2: torch.Size([277, 1284])\n",
      "PLSCR1: torch.Size([318, 1284])\n",
      "PMM2_1: torch.Size([246, 1284])\n",
      "PMM2_2: torch.Size([70, 1284])\n",
      "PNMA1: torch.Size([353, 1284])\n",
      "PNMA2: torch.Size([364, 1284])\n",
      "POGZ: torch.Size([1410, 1284])\n",
      "PPFIBP2: torch.Size([876, 1284])\n",
      "PPP1CB: torch.Size([327, 1284])\n",
      "PPP1R12B_1: torch.Size([386, 1284])\n",
      "PPP1R12B_2: torch.Size([184, 1284])\n",
      "PPP3CA_1: torch.Size([511, 1284])\n",
      "PPP3CA_2: torch.Size([521, 1284])\n",
      "PPP3R1: torch.Size([170, 1284])\n",
      "PQBP1_1: torch.Size([265, 1284])\n",
      "PRCC_1: torch.Size([491, 1284])\n",
      "PRCC_2: torch.Size([412, 1284])\n",
      "PRCC_3: torch.Size([459, 1284])\n",
      "PRDM14: torch.Size([571, 1284])\n",
      "PRKAR2B: torch.Size([418, 1284])\n",
      "PRMT2_1: torch.Size([433, 1284])\n",
      "PRMT2_2: torch.Size([286, 1284])\n",
      "PRMT2_3: torch.Size([48, 1284])\n",
      "PRR20A: torch.Size([221, 1284])\n",
      "PRTFDC1: torch.Size([225, 1284])\n",
      "PSMA3: torch.Size([255, 1284])\n",
      "PSMC6: torch.Size([389, 1284])\n",
      "PSME3: torch.Size([254, 1284])\n",
      "PSTPIP1_3: torch.Size([194, 1284])\n",
      "PSTPIP1: torch.Size([416, 1284])\n",
      "PSTPIP2_1: torch.Size([312, 1284])\n",
      "PSTPIP2_3: torch.Size([308, 1284])\n",
      "PTBP1: torch.Size([557, 1284])\n",
      "PTBP2: torch.Size([531, 1284])\n",
      "PTK2: torch.Size([1052, 1284])\n",
      "PTPRN: torch.Size([979, 1284])\n",
      "PUF60: torch.Size([559, 1284])\n",
      "RAB3IP: torch.Size([476, 1284])\n",
      "RABAC1: torch.Size([185, 1284])\n",
      "RARA: torch.Size([462, 1284])\n",
      "RARB: torch.Size([455, 1284])\n",
      "RASSF5: torch.Size([418, 1284])\n",
      "RBCK1: torch.Size([510, 1284])\n",
      "RBM10_2: torch.Size([930, 1284])\n",
      "RBM10: torch.Size([930, 1284])\n",
      "RBM12B: torch.Size([1001, 1284])\n",
      "RBM12: torch.Size([932, 1284])\n",
      "RBM14_1: torch.Size([669, 1284])\n",
      "RBM14_2: torch.Size([156, 1284])\n",
      "RBM14_3: torch.Size([119, 1284])\n",
      "RBM39: torch.Size([530, 1284])\n",
      "RBM5_1: torch.Size([546, 1284])\n",
      "RBM5_2: torch.Size([150, 1284])\n",
      "RBMY1F: torch.Size([496, 1284])\n",
      "RBPMS: torch.Size([196, 1284])\n",
      "RCOR3: torch.Size([495, 1284])\n",
      "REEP6: torch.Size([211, 1284])\n",
      "REL: torch.Size([619, 1284])\n",
      "RFX6: torch.Size([928, 1284])\n",
      "RHOXF2: torch.Size([288, 1284])\n",
      "RIN1_1: torch.Size([783, 1284])\n",
      "RIN1_2: torch.Size([721, 1284])\n",
      "RIN1_3: torch.Size([129, 1284])\n",
      "RINT1: torch.Size([792, 1284])\n",
      "RNF111: torch.Size([994, 1284])\n",
      "RNF40_1: torch.Size([1001, 1284])\n",
      "RNF40_2: torch.Size([956, 1284])\n",
      "RNF6_1: torch.Size([685, 1284])\n",
      "RNF6_2: torch.Size([176, 1284])\n",
      "RPGR_1: torch.Size([480, 1284])\n",
      "RPGR_2: torch.Size([510, 1284])\n",
      "RPGRIP1: torch.Size([1286, 1284])\n",
      "RTN3: torch.Size([1032, 1284])\n",
      "RUNDC3A: torch.Size([446, 1284])\n",
      "RXRB_1: torch.Size([533, 1284])\n",
      "RXRB_2: torch.Size([537, 1284])\n",
      "RXRB_3: torch.Size([508, 1284])\n",
      "RXRB_4: torch.Size([171, 1284])\n",
      "S100A1_1: torch.Size([94, 1284])\n",
      "S100A1_2: torch.Size([53, 1284])\n",
      "S100A1: torch.Size([94, 1284])\n",
      "S100A2: torch.Size([98, 1284])\n",
      "S100B_1: torch.Size([92, 1284])\n",
      "S100B_2: torch.Size([94, 1284])\n",
      "S100B: torch.Size([92, 1284])\n",
      "SBDS_1: torch.Size([250, 1284])\n",
      "SBDS_3: torch.Size([44, 1284])\n",
      "SCYL1: torch.Size([808, 1284])\n",
      "SDC3_1: torch.Size([370, 1284])\n",
      "SDC3_2: torch.Size([384, 1284])\n",
      "SDCCAG3: torch.Size([435, 1284])\n",
      "SEC22C_1: torch.Size([303, 1284])\n",
      "SEC22C_2: torch.Size([288, 1284])\n",
      "SEC22C_3: torch.Size([71, 1284])\n",
      "SEC63_1: torch.Size([760, 1284])\n",
      "SEPT1: torch.Size([372, 1284])\n",
      "SEPT6: torch.Size([434, 1284])\n",
      "SEPT9_3: torch.Size([353, 1284])\n",
      "SERPING1_1: torch.Size([500, 1284])\n",
      "SERPING1_3: torch.Size([43, 1284])\n",
      "SERPING1_4: torch.Size([174, 1284])\n",
      "SERTAD3: torch.Size([196, 1284])\n",
      "SF3B4: torch.Size([424, 1284])\n",
      "SFTPC_1: torch.Size([197, 1284])\n",
      "SFTPC_2: torch.Size([191, 1284])\n",
      "SGCA_1: torch.Size([387, 1284])\n",
      "SGCA_2: torch.Size([263, 1284])\n",
      "SGTA: torch.Size([313, 1284])\n",
      "SGTB: torch.Size([304, 1284])\n",
      "SHMT2_1: torch.Size([504, 1284])\n",
      "SHMT2_2: torch.Size([89, 1284])\n",
      "SIAH1: torch.Size([282, 1284])\n",
      "SKIL: torch.Size([684, 1284])\n",
      "SLC25A10_1: torch.Size([296, 1284])\n",
      "SLC25A10_2: torch.Size([287, 1284])\n",
      "SLC25A10_3: torch.Size([259, 1284])\n",
      "SMN2: torch.Size([294, 1284])\n",
      "SMUG1_1: torch.Size([177, 1284])\n",
      "SMUG1_2: torch.Size([270, 1284])\n",
      "SORBS3: torch.Size([671, 1284])\n",
      "SP4: torch.Size([784, 1284])\n",
      "SPAG5: torch.Size([1193, 1284])\n",
      "SPERT: torch.Size([448, 1284])\n",
      "SPRY2: torch.Size([315, 1284])\n",
      "SRRM1_1: torch.Size([904, 1284])\n",
      "SRRM1_2: torch.Size([918, 1284])\n",
      "SRSF10_1: torch.Size([262, 1284])\n",
      "SRSF10_2: torch.Size([40, 1284])\n",
      "SRSF11: torch.Size([484, 1284])\n",
      "SS18L1: torch.Size([396, 1284])\n",
      "SSX2IP: torch.Size([614, 1284])\n",
      "STAC3: torch.Size([364, 1284])\n",
      "STAR_1: torch.Size([285, 1284])\n",
      "STK25_1: torch.Size([426, 1284])\n",
      "STK25_2: torch.Size([90, 1284])\n",
      "STK25_3: torch.Size([349, 1284])\n",
      "STRBP_1: torch.Size([672, 1284])\n",
      "STRBP_2: torch.Size([657, 1284])\n",
      "STUB1: torch.Size([303, 1284])\n",
      "STX11: torch.Size([287, 1284])\n",
      "SUCLA2_1: torch.Size([463, 1284])\n",
      "SUCLA2_2: torch.Size([315, 1284])\n",
      "SUMO1P1: torch.Size([101, 1284])\n",
      "SUMO1: torch.Size([101, 1284])\n",
      "SYCE1: torch.Size([351, 1284])\n",
      "TACC1: torch.Size([805, 1284])\n",
      "TADA2A: torch.Size([443, 1284])\n",
      "TADA3: torch.Size([432, 1284])\n",
      "TAX1BP1: torch.Size([789, 1284])\n",
      "TBL2_3: torch.Size([316, 1284])\n",
      "TCF12: torch.Size([682, 1284])\n",
      "TCF4: torch.Size([667, 1284])\n",
      "TCL1A: torch.Size([114, 1284])\n",
      "TEAD4_1: torch.Size([361, 1284])\n",
      "TEAD4_2: torch.Size([146, 1284])\n",
      "TEAD4_3: torch.Size([238, 1284])\n",
      "TEKT1: torch.Size([418, 1284])\n",
      "TENC1: torch.Size([1409, 1284])\n",
      "TEX11: torch.Size([940, 1284])\n",
      "TEX9_1: torch.Size([391, 1284])\n",
      "TEX9_4: torch.Size([40, 1284])\n",
      "TEX9_5: torch.Size([131, 1284])\n",
      "TFCP2: torch.Size([502, 1284])\n",
      "TFDP1: torch.Size([410, 1284])\n",
      "TFDP2: torch.Size([446, 1284])\n",
      "TFG: torch.Size([400, 1284])\n",
      "TFIP11: torch.Size([837, 1284])\n",
      "THAP1: torch.Size([213, 1284])\n",
      "TMCC2: torch.Size([709, 1284])\n",
      "TMEM159: torch.Size([161, 1284])\n",
      "TMEM43_1: torch.Size([400, 1284])\n",
      "TMEM43_2: torch.Size([269, 1284])\n",
      "TMEM67_1: torch.Size([985, 1284])\n",
      "TMEM67_2: torch.Size([219, 1284])\n",
      "TMEM67_3: torch.Size([134, 1284])\n",
      "TMEM79: torch.Size([394, 1284])\n",
      "TNIP1: torch.Size([636, 1284])\n",
      "TOX4: torch.Size([621, 1284])\n",
      "TP53BP2: torch.Size([1128, 1284])\n",
      "TP53: torch.Size([393, 1284])\n",
      "TPM1_2: torch.Size([284, 1284])\n",
      "TRAF1: torch.Size([416, 1284])\n",
      "TRAF2: torch.Size([501, 1284])\n",
      "TRAF4: torch.Size([470, 1284])\n",
      "TRIM15: torch.Size([465, 1284])\n",
      "TRIM17: torch.Size([477, 1284])\n",
      "TRIM23: torch.Size([574, 1284])\n",
      "TRIM27: torch.Size([513, 1284])\n",
      "TRIM2: torch.Size([744, 1284])\n",
      "TRIM32: torch.Size([653, 1284])\n",
      "TRIM37: torch.Size([964, 1284])\n",
      "TRIM42: torch.Size([723, 1284])\n",
      "TRIM69: torch.Size([500, 1284])\n",
      "TRIM9: torch.Size([710, 1284])\n",
      "TRIP13: torch.Size([432, 1284])\n",
      "TRIP6: torch.Size([476, 1284])\n",
      "TSG101: torch.Size([390, 1284])\n",
      "TSGA10: torch.Size([698, 1284])\n",
      "TSTD2_1: torch.Size([489, 1284])\n",
      "TSTD2_2: torch.Size([75, 1284])\n",
      "TTC12: torch.Size([705, 1284])\n",
      "TTC1: torch.Size([292, 1284])\n",
      "U2AF1: torch.Size([240, 1284])\n",
      "UBL7: torch.Size([380, 1284])\n",
      "UBQLN1: torch.Size([589, 1284])\n",
      "UCK1_1: torch.Size([201, 1284])\n",
      "UCK1_3: torch.Size([232, 1284])\n",
      "UCK1_5: torch.Size([209, 1284])\n",
      "UCK1: torch.Size([277, 1284])\n",
      "UPP2_1: torch.Size([317, 1284])\n",
      "UPP2_2: torch.Size([281, 1284])\n",
      "UPP2_3: torch.Size([264, 1284])\n",
      "UPP2_4: torch.Size([65, 1284])\n",
      "UPP2: torch.Size([317, 1284])\n",
      "USHBP1: torch.Size([703, 1284])\n",
      "USP53: torch.Size([1073, 1284])\n",
      "VAC14: torch.Size([782, 1284])\n",
      "VIPAR: torch.Size([493, 1284])\n",
      "VPS28_1: torch.Size([221, 1284])\n",
      "VPS28_2: torch.Size([204, 1284])\n",
      "VPS33B_1: torch.Size([617, 1284])\n",
      "VPS33B_2: torch.Size([53, 1284])\n",
      "VPS33B_3: torch.Size([71, 1284])\n",
      "VPS37B: torch.Size([285, 1284])\n",
      "VPS52: torch.Size([723, 1284])\n",
      "WAC: torch.Size([647, 1284])\n",
      "WASL: torch.Size([505, 1284])\n",
      "WWP2: torch.Size([870, 1284])\n",
      "YARS_1: torch.Size([528, 1284])\n",
      "YARS_2: torch.Size([44, 1284])\n",
      "ZBTB16_1: torch.Size([673, 1284])\n",
      "ZBTB1: torch.Size([713, 1284])\n",
      "ZBTB24: torch.Size([697, 1284])\n",
      "ZBTB26: torch.Size([441, 1284])\n",
      "ZBTB32_1: torch.Size([302, 1284])\n",
      "ZBTB32_2: torch.Size([198, 1284])\n",
      "ZBTB7B: torch.Size([539, 1284])\n",
      "ZBTB8A: torch.Size([441, 1284])\n",
      "ZC4H2: torch.Size([224, 1284])\n",
      "ZCWPW1_1: torch.Size([477, 1284])\n",
      "ZCWPW1_2: torch.Size([529, 1284])\n",
      "ZCWPW1_4: torch.Size([404, 1284])\n",
      "ZCWPW1_5: torch.Size([403, 1284])\n",
      "ZCWPW1_6: torch.Size([376, 1284])\n",
      "ZFP64: torch.Size([645, 1284])\n",
      "ZFY: torch.Size([801, 1284])\n",
      "ZFYVE19: torch.Size([471, 1284])\n",
      "ZGPAT_1: torch.Size([511, 1284])\n",
      "ZGPAT_2: torch.Size([523, 1284])\n",
      "ZKSCAN4_1: torch.Size([545, 1284])\n",
      "ZKSCAN4_3: torch.Size([149, 1284])\n",
      "ZKSCAN4: torch.Size([545, 1284])\n",
      "ZMAT4: torch.Size([229, 1284])\n",
      "ZMIZ2: torch.Size([920, 1284])\n",
      "ZNF167: torch.Size([754, 1284])\n",
      "ZNF341: torch.Size([854, 1284])\n",
      "ZNF397: torch.Size([534, 1284])\n",
      "ZNF434: torch.Size([697, 1284])\n",
      "ZNF446: torch.Size([450, 1284])\n",
      "ZNF471: torch.Size([626, 1284])\n",
      "ZNF473: torch.Size([871, 1284])\n",
      "ZNF483: torch.Size([744, 1284])\n",
      "ZNF496: torch.Size([587, 1284])\n",
      "ZNF688_1: torch.Size([276, 1284])\n",
      "ZNF688_2: torch.Size([83, 1284])\n",
      "ZNF688_4: torch.Size([238, 1284])\n",
      "ZSCAN20: torch.Size([1043, 1284])\n",
      "ZSCAN22: torch.Size([491, 1284])\n",
      "ZYX: torch.Size([572, 1284])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.data import InMemoryDataset, Data\n",
    "from tqdm import tqdm\n",
    "from Bio.PDB import PDBParser\n",
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "import scipy.spatial.distance as dist\n",
    "import biotite.structure.io.pdb as pdb\n",
    "\n",
    "def get_edge(coords, protein_name, threshold, pesto_dict):\n",
    "    \"\"\"Compute edge connections for a protein.\"\"\"\n",
    "    res_probs = pesto_dict[protein_name]\n",
    "    dists = dist.cdist(coords, coords)\n",
    "    edges = []\n",
    "    for i in range(len(dists)):\n",
    "        for j in range(len(dists)):\n",
    "            if res_probs[i] >= 0.1 and res_probs[j] >= 0.1 and i != j and dists[i, j] < threshold  and abs(i - j) != 1:\n",
    "                edges.append((i, j))\n",
    "            if i != j and dists[i, j] < threshold  and abs(i - j) != 1:\n",
    "                edges.append((i, j))\n",
    "    return edges\n",
    "\n",
    "# 生成蛋白质的图数据\n",
    "def generate_edge_index(esm_file, pdb_file, protein_name, threshold, pesto_dict):\n",
    "    esm_feature = torch.load(esm_file)['representations'][33]\n",
    "    protein_feature_esm = torch.load(esm_file)['mean_representations'][33]\n",
    "    \n",
    "    with open(pdb_file, 'r') as f:\n",
    "        model = pdb.PDBFile.read(f).get_structure(model=1)\n",
    "    x = esm_feature\n",
    "    esm2 = protein_feature_esm\n",
    "    coord = [i.coord for i in model if i.atom_name == \"CA\"]\n",
    "    edge_index = torch.tensor(get_edge(coord, protein_name, threshold, pesto_dict)).T\n",
    "    return Data(x=x, edge_index=edge_index, esm2=esm2)\n",
    "\n",
    "# Generate the graph and merge features\n",
    "def generate_protein_graphs(pdb_list_file, pdb_dir, esm_dir, threshold, pesto_dict, secondary_dict):\n",
    "    with open(pdb_list_file, 'r') as file:\n",
    "        f_names = [protein_name.rstrip() for protein_name in file]\n",
    "        pdb_files = [os.path.join(pdb_dir, protein_name + '.pdb') for protein_name in f_names]\n",
    "        esm_files = [os.path.join(esm_dir, protein_name + '.pt') for protein_name in f_names]\n",
    "    p = Pool(5)\n",
    "    result = [[protein_name, p.apply_async(generate_edge_index, (esm_file, pdb_file, protein_name, threshold, pesto_dict))] \n",
    "              for esm_file, pdb_file, protein_name in zip(esm_files, pdb_files, f_names)]\n",
    "    p.close()\n",
    "    p.join()\n",
    "    protein_dict = {k: v.get() for (k, v) in result}\n",
    "    for protein_name, data in protein_dict.items():\n",
    "        esm_fea = protein_dict[protein_name].x\n",
    "        protein_dict[protein_name].x = torch.cat((secondary_dict[protein_name], esm_fea), dim=1)\n",
    "    \n",
    "    return protein_dict\n",
    "\n",
    "pdb_list_file = '/mnt/disk1/guoxiaokun/isoform/double.GCN/pdb.list.txt'\n",
    "pdb_dir = '/mnt/disk1/guoxiaokun/isoform/double.GCN/PDB/'\n",
    "esm_dir = '/mnt/disk1/guoxiaokun/isoform/double.GCN/isoform_esm2/'\n",
    "threshold = 8\n",
    "protein_dict = generate_protein_graphs(pdb_list_file, pdb_dir, esm_dir, threshold, pesto_dict, secondary_dict)\n",
    "\n",
    "# The feature of protein\n",
    "for protein_name, data in protein_dict.items():\n",
    "    print(f\"{protein_name}: {data.x.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn import metrics\n",
    "import random\n",
    "import pandas as pd\n",
    "import scipy.sparse as spp\n",
    "\n",
    "class ProteinDataLoader:\n",
    "    def __init__(self, protein_dict, train_file, test_file, batch_size=3, seed=2066):\n",
    "        self.device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "        self.protein_dict = protein_dict\n",
    "        self.batch_size = batch_size\n",
    "        self.seed = seed\n",
    "        self.setup_seed(self.seed)\n",
    "        \n",
    "        # Load train and test data\n",
    "        self.train_file = train_file\n",
    "        self.test_file = test_file\n",
    "        self.train_df = pd.read_csv(self.train_file, sep=\"\\t\", header=None)\n",
    "        self.test_df = pd.read_csv(self.test_file, sep=\"\\t\", header=None)\n",
    "        \n",
    "        # Prepare datasets and dataloaders\n",
    "        self.test_data = self.generate_data(self.test_df)\n",
    "        self.test_dataset = ProteinDataset(self.test_data)\n",
    "        self.test_loader = DataLoader(self.test_dataset, batch_size=self.batch_size, shuffle=False, collate_fn=self.collate_fn)\n",
    "\n",
    "        self.raw_train_data = self.generate_data(self.train_df)\n",
    "        self.raw_train_dataset = ProteinDataset(self.raw_train_data)\n",
    "        self.raw_train_loader = DataLoader(self.raw_train_dataset, batch_size=self.batch_size, shuffle=True, collate_fn=self.collate_fn)\n",
    "    \n",
    "    def setup_seed(self, seed):\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "    def generate_data(self, df):\n",
    "        \"\"\"Generate data list from dataframe and protein dictionary.\"\"\"\n",
    "        data_list = []\n",
    "        for i in range(len(df)):\n",
    "            protein1, protein2, label = df.iloc[i]\n",
    "            data1 = self.protein_dict[protein1]\n",
    "            data2 = self.protein_dict[protein2]\n",
    "            data_list.append((data1, data2, torch.tensor([label], dtype=torch.float).to(self.device)))\n",
    "        return data_list\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        \"\"\"Custom collate function for DataLoader.\"\"\"\n",
    "        data1 = [item[0] for item in batch]\n",
    "        data2 = [item[1] for item in batch]\n",
    "        label = torch.stack([item[2] for item in batch])\n",
    "        return [data1, data2, label]\n",
    "\n",
    "class ProteinDataset(Dataset):\n",
    "    \"\"\"Custom Dataset class for protein interaction data.\"\"\"\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "def weights_init(m):\n",
    "     if isinstance(m, (nn.Conv1d, nn.Linear)):\n",
    "       nn.init.kaiming_normal_(m.weight, mode='fan_in',\n",
    "                                 nonlinearity='leaky_relu')\n",
    "       \n",
    "train_file = 'train.txt'\n",
    "test_file = 'test.txt'\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "# Create an instance of ProteinDataLoader\n",
    "data_loader = ProteinDataLoader(protein_dict, train_file, test_file)\n",
    "\n",
    "test_loader = data_loader.test_loader\n",
    "raw_train_loader = data_loader.raw_train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "\n",
    "# GCN模型定义\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_features, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_features, 512).to(device)\n",
    "        self.conv2 = GCNConv(512, 256).to(device)\n",
    "        \n",
    "        self.cnn1 = torch.nn.Conv1d(1, 8, kernel_size=2, stride=1) \n",
    "        self.normal_layer3 = torch.nn.Linear(511, 511)\n",
    "\n",
    "        self.cnn2 = torch.nn.Conv1d(8, 16, kernel_size=2, stride=1) \n",
    "        self.normal_layer4 = torch.nn.Linear(510, 510)\n",
    "\n",
    "        self.fc1 = torch.nn.Linear(16*510, 2560).to(device)\n",
    "        self.fc2 = torch.nn.Linear(2560, 512).to(device)\n",
    "        self.fc3 = torch.nn.Linear(512, 128).to(device)\n",
    "        self.fc4 = torch.nn.Linear(128, 1).to(device)\n",
    "        self.fc5 = torch.nn.Linear(128, 1).to(device)\n",
    "        self.elu = torch.nn.ELU()\n",
    "        self.dropout = torch.nn.Dropout(0.5).to(device)  # Dropout layer with dropout rate of 0.2\n",
    "\n",
    "    def forward(self, data1, data2):\n",
    "        x1, edge_index1 = data1.x.to(device), data1.edge_index.to(device)\n",
    "        x2, edge_index2 = data2.x.to(device), data2.edge_index.to(device)\n",
    "\n",
    "        x1 = F.leaky_relu(self.conv1(x1, edge_index1))   \n",
    "        x1 = F.leaky_relu(self.conv2(x1, edge_index1))\n",
    "        x1 = torch.mean(x1, 0, keepdim=True)  # 对所有节点的特征进行平均池化\n",
    "\n",
    "        x2 = F.leaky_relu(self.conv1(x2, edge_index2))\n",
    "        x2 = F.leaky_relu(self.conv2(x2, edge_index2))\n",
    "        x2 = torch.mean(x2, 0, keepdim=True)  # 对所有节点的特征进行平均池化\n",
    "        out = torch.cat((x1,x2),dim=1)\n",
    "        \n",
    "        out = F.leaky_relu(self.cnn1(out))\n",
    "        out = self.normal_layer3(out)\n",
    "        out = F.leaky_relu(self.cnn2(out))\n",
    "        out = self.normal_layer4(out).view(-1)\n",
    "        \n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.fc3(out)\n",
    "        out = self.fc4(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kf: 0\n",
      "\n",
      "epoch: 0, train_loss: 1.2583, val_loss: 0.8373, AUC: 0.5657\n",
      "New best model found with AUC: 0.5657. Model saved to best_model_fold0.pth\n",
      "epoch: 1, train_loss: 0.7120, val_loss: 0.6828, AUC: 0.6097\n",
      "New best model found with AUC: 0.6097. Model saved to best_model_fold0.pth\n",
      "epoch: 2, train_loss: 0.6878, val_loss: 0.6633, AUC: 0.6155\n",
      "New best model found with AUC: 0.6155. Model saved to best_model_fold0.pth\n",
      "epoch: 3, train_loss: 0.6650, val_loss: 0.6757, AUC: 0.6097\n",
      "epoch: 4, train_loss: 0.6674, val_loss: 0.6684, AUC: 0.6159\n",
      "New best model found with AUC: 0.6159. Model saved to best_model_fold0.pth\n",
      "epoch: 5, train_loss: 0.6551, val_loss: 0.6559, AUC: 0.6440\n",
      "New best model found with AUC: 0.6440. Model saved to best_model_fold0.pth\n",
      "epoch: 6, train_loss: 0.6443, val_loss: 0.6506, AUC: 0.6564\n",
      "New best model found with AUC: 0.6564. Model saved to best_model_fold0.pth\n",
      "epoch: 7, train_loss: 0.6354, val_loss: 0.6635, AUC: 0.6735\n",
      "New best model found with AUC: 0.6735. Model saved to best_model_fold0.pth\n",
      "epoch: 8, train_loss: 0.6375, val_loss: 0.6782, AUC: 0.6917\n",
      "New best model found with AUC: 0.6917. Model saved to best_model_fold0.pth\n",
      "epoch: 9, train_loss: 0.6199, val_loss: 0.6465, AUC: 0.6909\n",
      "epoch: 10, train_loss: 0.6221, val_loss: 0.6908, AUC: 0.6824\n",
      "epoch: 11, train_loss: 0.5895, val_loss: 0.9610, AUC: 0.6924\n",
      "New best model found with AUC: 0.6924. Model saved to best_model_fold0.pth\n",
      "epoch: 12, train_loss: 0.5845, val_loss: 0.7203, AUC: 0.7275\n",
      "New best model found with AUC: 0.7275. Model saved to best_model_fold0.pth\n",
      "epoch: 13, train_loss: 0.5460, val_loss: 0.6165, AUC: 0.7501\n",
      "New best model found with AUC: 0.7501. Model saved to best_model_fold0.pth\n",
      "epoch: 14, train_loss: 0.5294, val_loss: 0.6262, AUC: 0.7463\n",
      "epoch: 15, train_loss: 0.5057, val_loss: 0.6305, AUC: 0.7407\n",
      "epoch: 16, train_loss: 0.4922, val_loss: 0.5748, AUC: 0.7793\n",
      "New best model found with AUC: 0.7793. Model saved to best_model_fold0.pth\n",
      "epoch: 17, train_loss: 0.4485, val_loss: 0.6379, AUC: 0.7823\n",
      "New best model found with AUC: 0.7823. Model saved to best_model_fold0.pth\n",
      "epoch: 18, train_loss: 0.4162, val_loss: 0.6799, AUC: 0.8099\n",
      "New best model found with AUC: 0.8099. Model saved to best_model_fold0.pth\n",
      "epoch: 19, train_loss: 0.3834, val_loss: 0.6504, AUC: 0.8062\n",
      "epoch: 20, train_loss: 0.3506, val_loss: 0.6174, AUC: 0.8141\n",
      "New best model found with AUC: 0.8141. Model saved to best_model_fold0.pth\n",
      "epoch: 21, train_loss: 0.3122, val_loss: 0.8714, AUC: 0.7965\n",
      "epoch: 22, train_loss: 0.2932, val_loss: 0.7072, AUC: 0.8136\n",
      "Epoch 00023: reducing learning rate of group 0 to 5.0000e-05.\n",
      "epoch: 23, train_loss: 0.1944, val_loss: 0.8458, AUC: 0.8284\n",
      "New best model found with AUC: 0.8284. Model saved to best_model_fold0.pth\n",
      "epoch: 24, train_loss: 0.1624, val_loss: 0.9804, AUC: 0.8330\n",
      "New best model found with AUC: 0.8330. Model saved to best_model_fold0.pth\n",
      "epoch: 25, train_loss: 0.1420, val_loss: 1.0841, AUC: 0.8059\n",
      "epoch: 26, train_loss: 0.1400, val_loss: 1.1012, AUC: 0.8257\n",
      "epoch: 27, train_loss: 0.1191, val_loss: 1.2483, AUC: 0.8169\n",
      "epoch: 28, train_loss: 0.1447, val_loss: 0.8441, AUC: 0.8216\n",
      "Epoch 00029: reducing learning rate of group 0 to 2.5000e-05.\n",
      "epoch: 29, train_loss: 0.0764, val_loss: 1.2060, AUC: 0.8279\n",
      "epoch: 30, train_loss: 0.0725, val_loss: 1.4013, AUC: 0.8263\n",
      "epoch: 31, train_loss: 0.0721, val_loss: 1.3067, AUC: 0.8268\n",
      "epoch: 32, train_loss: 0.0627, val_loss: 1.3316, AUC: 0.8219\n",
      "epoch: 33, train_loss: 0.0627, val_loss: 1.2998, AUC: 0.8290\n",
      "epoch: 34, train_loss: 0.0615, val_loss: 1.4239, AUC: 0.8209\n",
      "Epoch 00035: reducing learning rate of group 0 to 1.2500e-05.\n",
      "epoch: 35, train_loss: 0.0438, val_loss: 1.5118, AUC: 0.8256\n",
      "epoch: 36, train_loss: 0.0371, val_loss: 1.6177, AUC: 0.8243\n",
      "epoch: 37, train_loss: 0.0344, val_loss: 1.7620, AUC: 0.8291\n",
      "epoch: 38, train_loss: 0.0428, val_loss: 1.6157, AUC: 0.8271\n",
      "epoch: 39, train_loss: 0.0326, val_loss: 1.7094, AUC: 0.8272\n",
      "epoch: 40, train_loss: 0.0310, val_loss: 1.7527, AUC: 0.8221\n",
      "Epoch 00041: reducing learning rate of group 0 to 6.2500e-06.\n",
      "epoch: 41, train_loss: 0.0276, val_loss: 1.8192, AUC: 0.8268\n",
      "epoch: 42, train_loss: 0.0208, val_loss: 2.0466, AUC: 0.8267\n",
      "epoch: 43, train_loss: 0.0223, val_loss: 2.1843, AUC: 0.8282\n",
      "epoch: 44, train_loss: 0.0215, val_loss: 2.2418, AUC: 0.8271\n",
      "epoch: 45, train_loss: 0.0208, val_loss: 2.2829, AUC: 0.8268\n",
      "epoch: 46, train_loss: 0.0192, val_loss: 2.3648, AUC: 0.8261\n",
      "Epoch 00047: reducing learning rate of group 0 to 3.1250e-06.\n",
      "epoch: 47, train_loss: 0.0158, val_loss: 2.4595, AUC: 0.8261\n",
      "epoch: 48, train_loss: 0.0137, val_loss: 2.5845, AUC: 0.8261\n",
      "epoch: 49, train_loss: 0.0127, val_loss: 2.7522, AUC: 0.8264\n",
      "Best AUC for fold 0: 0.8330\n",
      "\n",
      "kf: 1\n",
      "\n",
      "epoch: 0, train_loss: 2.0039, val_loss: 0.7412, AUC: 0.5366\n",
      "New best model found with AUC: 0.5366. Model saved to best_model_fold1.pth\n",
      "epoch: 1, train_loss: 0.7045, val_loss: 0.6775, AUC: 0.6059\n",
      "New best model found with AUC: 0.6059. Model saved to best_model_fold1.pth\n",
      "epoch: 2, train_loss: 0.6793, val_loss: 0.7329, AUC: 0.5998\n",
      "epoch: 3, train_loss: 0.6837, val_loss: 0.7363, AUC: 0.6341\n",
      "New best model found with AUC: 0.6341. Model saved to best_model_fold1.pth\n",
      "epoch: 4, train_loss: 0.6745, val_loss: 0.8998, AUC: 0.6483\n",
      "New best model found with AUC: 0.6483. Model saved to best_model_fold1.pth\n",
      "epoch: 5, train_loss: 0.6787, val_loss: 0.6845, AUC: 0.6608\n",
      "New best model found with AUC: 0.6608. Model saved to best_model_fold1.pth\n",
      "epoch: 6, train_loss: 0.6535, val_loss: 0.6756, AUC: 0.6603\n",
      "epoch: 7, train_loss: 0.6404, val_loss: 0.6448, AUC: 0.6765\n",
      "New best model found with AUC: 0.6765. Model saved to best_model_fold1.pth\n",
      "epoch: 8, train_loss: 0.6337, val_loss: 0.6466, AUC: 0.6759\n",
      "epoch: 9, train_loss: 0.6522, val_loss: 0.6598, AUC: 0.6890\n",
      "New best model found with AUC: 0.6890. Model saved to best_model_fold1.pth\n",
      "epoch: 10, train_loss: 0.6233, val_loss: 0.6767, AUC: 0.6931\n",
      "New best model found with AUC: 0.6931. Model saved to best_model_fold1.pth\n",
      "epoch: 11, train_loss: 0.6070, val_loss: 0.6424, AUC: 0.6920\n",
      "epoch: 12, train_loss: 0.6090, val_loss: 0.7223, AUC: 0.6988\n",
      "New best model found with AUC: 0.6988. Model saved to best_model_fold1.pth\n",
      "epoch: 13, train_loss: 0.6065, val_loss: 0.6424, AUC: 0.6959\n",
      "epoch: 14, train_loss: 0.5964, val_loss: 0.6386, AUC: 0.7005\n",
      "New best model found with AUC: 0.7005. Model saved to best_model_fold1.pth\n",
      "epoch: 15, train_loss: 0.5892, val_loss: 0.7168, AUC: 0.6972\n",
      "epoch: 16, train_loss: 0.5645, val_loss: 0.6744, AUC: 0.7084\n",
      "New best model found with AUC: 0.7084. Model saved to best_model_fold1.pth\n",
      "epoch: 17, train_loss: 0.5669, val_loss: 0.6737, AUC: 0.7169\n",
      "New best model found with AUC: 0.7169. Model saved to best_model_fold1.pth\n",
      "epoch: 18, train_loss: 0.5481, val_loss: 0.6251, AUC: 0.7437\n",
      "New best model found with AUC: 0.7437. Model saved to best_model_fold1.pth\n",
      "epoch: 19, train_loss: 0.5319, val_loss: 0.7279, AUC: 0.7356\n",
      "epoch: 20, train_loss: 0.5242, val_loss: 0.6259, AUC: 0.7449\n",
      "New best model found with AUC: 0.7449. Model saved to best_model_fold1.pth\n",
      "epoch: 21, train_loss: 0.4929, val_loss: 0.7030, AUC: 0.7511\n",
      "New best model found with AUC: 0.7511. Model saved to best_model_fold1.pth\n",
      "epoch: 22, train_loss: 0.4804, val_loss: 0.6596, AUC: 0.7566\n",
      "New best model found with AUC: 0.7566. Model saved to best_model_fold1.pth\n",
      "epoch: 23, train_loss: 0.4690, val_loss: 0.6945, AUC: 0.7591\n",
      "New best model found with AUC: 0.7591. Model saved to best_model_fold1.pth\n",
      "epoch: 24, train_loss: 0.4513, val_loss: 0.6121, AUC: 0.7918\n",
      "New best model found with AUC: 0.7918. Model saved to best_model_fold1.pth\n",
      "epoch: 25, train_loss: 0.4236, val_loss: 0.7618, AUC: 0.7562\n",
      "epoch: 26, train_loss: 0.4021, val_loss: 0.7844, AUC: 0.7847\n",
      "epoch: 27, train_loss: 0.3808, val_loss: 0.8455, AUC: 0.7908\n",
      "epoch: 28, train_loss: 0.3640, val_loss: 0.6981, AUC: 0.7856\n",
      "epoch: 29, train_loss: 0.3296, val_loss: 0.7381, AUC: 0.7941\n",
      "New best model found with AUC: 0.7941. Model saved to best_model_fold1.pth\n",
      "epoch: 30, train_loss: 0.2943, val_loss: 0.9048, AUC: 0.7935\n",
      "Epoch 00031: reducing learning rate of group 0 to 5.0000e-05.\n",
      "epoch: 31, train_loss: 0.2126, val_loss: 1.0061, AUC: 0.7912\n",
      "epoch: 32, train_loss: 0.1955, val_loss: 0.9836, AUC: 0.7930\n",
      "epoch: 33, train_loss: 0.1723, val_loss: 1.3122, AUC: 0.7890\n",
      "epoch: 34, train_loss: 0.1537, val_loss: 1.1907, AUC: 0.7859\n",
      "epoch: 35, train_loss: 0.1407, val_loss: 1.4887, AUC: 0.7902\n",
      "epoch: 36, train_loss: 0.1376, val_loss: 1.5263, AUC: 0.7942\n",
      "New best model found with AUC: 0.7942. Model saved to best_model_fold1.pth\n",
      "Epoch 00037: reducing learning rate of group 0 to 2.5000e-05.\n",
      "epoch: 37, train_loss: 0.0907, val_loss: 1.7200, AUC: 0.7900\n",
      "epoch: 38, train_loss: 0.0847, val_loss: 1.5789, AUC: 0.7871\n",
      "epoch: 39, train_loss: 0.0754, val_loss: 1.6286, AUC: 0.7921\n",
      "epoch: 40, train_loss: 0.0725, val_loss: 1.8220, AUC: 0.7886\n",
      "epoch: 41, train_loss: 0.0669, val_loss: 1.9965, AUC: 0.7976\n",
      "New best model found with AUC: 0.7976. Model saved to best_model_fold1.pth\n",
      "epoch: 42, train_loss: 0.0732, val_loss: 1.6371, AUC: 0.7861\n",
      "Epoch 00043: reducing learning rate of group 0 to 1.2500e-05.\n",
      "epoch: 43, train_loss: 0.0503, val_loss: 2.0314, AUC: 0.7962\n",
      "epoch: 44, train_loss: 0.0413, val_loss: 2.1884, AUC: 0.7953\n",
      "epoch: 45, train_loss: 0.0448, val_loss: 2.2468, AUC: 0.7930\n",
      "epoch: 46, train_loss: 0.0426, val_loss: 2.2169, AUC: 0.7968\n",
      "epoch: 47, train_loss: 0.0389, val_loss: 2.2979, AUC: 0.7973\n",
      "epoch: 48, train_loss: 0.0431, val_loss: 2.3250, AUC: 0.7927\n",
      "Epoch 00049: reducing learning rate of group 0 to 6.2500e-06.\n",
      "epoch: 49, train_loss: 0.0288, val_loss: 2.4345, AUC: 0.7959\n",
      "Best AUC for fold 1: 0.7976\n",
      "\n",
      "kf: 2\n",
      "\n",
      "epoch: 0, train_loss: 1.5343, val_loss: 0.7535, AUC: 0.5150\n",
      "New best model found with AUC: 0.5150. Model saved to best_model_fold2.pth\n",
      "epoch: 1, train_loss: 0.7282, val_loss: 0.7023, AUC: 0.5683\n",
      "New best model found with AUC: 0.5683. Model saved to best_model_fold2.pth\n",
      "epoch: 2, train_loss: 0.7055, val_loss: 0.7012, AUC: 0.6408\n",
      "New best model found with AUC: 0.6408. Model saved to best_model_fold2.pth\n",
      "epoch: 3, train_loss: 0.6786, val_loss: 0.7708, AUC: 0.6220\n",
      "epoch: 4, train_loss: 0.6607, val_loss: 0.6603, AUC: 0.6674\n",
      "New best model found with AUC: 0.6674. Model saved to best_model_fold2.pth\n",
      "epoch: 5, train_loss: 0.6591, val_loss: 0.7279, AUC: 0.6607\n",
      "epoch: 6, train_loss: 0.6553, val_loss: 0.6642, AUC: 0.6996\n",
      "New best model found with AUC: 0.6996. Model saved to best_model_fold2.pth\n",
      "epoch: 7, train_loss: 0.6453, val_loss: 0.6664, AUC: 0.6751\n",
      "epoch: 8, train_loss: 0.6316, val_loss: 0.6260, AUC: 0.7040\n",
      "New best model found with AUC: 0.7040. Model saved to best_model_fold2.pth\n",
      "epoch: 9, train_loss: 0.6190, val_loss: 0.6467, AUC: 0.6954\n",
      "epoch: 10, train_loss: 0.6037, val_loss: 0.7165, AUC: 0.6921\n",
      "epoch: 11, train_loss: 0.5995, val_loss: 0.6676, AUC: 0.7215\n",
      "New best model found with AUC: 0.7215. Model saved to best_model_fold2.pth\n",
      "epoch: 12, train_loss: 0.5745, val_loss: 0.7368, AUC: 0.7067\n",
      "epoch: 13, train_loss: 0.5653, val_loss: 0.6207, AUC: 0.7415\n",
      "New best model found with AUC: 0.7415. Model saved to best_model_fold2.pth\n",
      "epoch: 14, train_loss: 0.5238, val_loss: 0.6292, AUC: 0.7487\n",
      "New best model found with AUC: 0.7487. Model saved to best_model_fold2.pth\n",
      "epoch: 15, train_loss: 0.4915, val_loss: 0.6481, AUC: 0.7732\n",
      "New best model found with AUC: 0.7732. Model saved to best_model_fold2.pth\n",
      "epoch: 16, train_loss: 0.4642, val_loss: 0.6759, AUC: 0.7809\n",
      "New best model found with AUC: 0.7809. Model saved to best_model_fold2.pth\n",
      "epoch: 17, train_loss: 0.4257, val_loss: 0.7379, AUC: 0.7931\n",
      "New best model found with AUC: 0.7931. Model saved to best_model_fold2.pth\n",
      "epoch: 18, train_loss: 0.3936, val_loss: 0.8044, AUC: 0.7874\n",
      "epoch: 19, train_loss: 0.3519, val_loss: 0.6485, AUC: 0.7811\n",
      "Epoch 00020: reducing learning rate of group 0 to 5.0000e-05.\n",
      "epoch: 20, train_loss: 0.2229, val_loss: 0.8692, AUC: 0.7987\n",
      "New best model found with AUC: 0.7987. Model saved to best_model_fold2.pth\n",
      "epoch: 21, train_loss: 0.1889, val_loss: 0.9408, AUC: 0.7980\n",
      "epoch: 22, train_loss: 0.1860, val_loss: 0.8003, AUC: 0.7967\n",
      "epoch: 23, train_loss: 0.1539, val_loss: 1.0427, AUC: 0.7940\n",
      "epoch: 24, train_loss: 0.1349, val_loss: 1.0343, AUC: 0.7860\n",
      "epoch: 25, train_loss: 0.1301, val_loss: 1.1141, AUC: 0.7959\n",
      "Epoch 00026: reducing learning rate of group 0 to 2.5000e-05.\n",
      "epoch: 26, train_loss: 0.0873, val_loss: 1.2518, AUC: 0.7979\n",
      "epoch: 27, train_loss: 0.0792, val_loss: 1.1297, AUC: 0.8007\n",
      "New best model found with AUC: 0.8007. Model saved to best_model_fold2.pth\n",
      "epoch: 28, train_loss: 0.0717, val_loss: 1.3366, AUC: 0.7948\n",
      "epoch: 29, train_loss: 0.0636, val_loss: 1.2942, AUC: 0.8022\n",
      "New best model found with AUC: 0.8022. Model saved to best_model_fold2.pth\n",
      "epoch: 30, train_loss: 0.0682, val_loss: 1.3170, AUC: 0.7916\n",
      "epoch: 31, train_loss: 0.0632, val_loss: 1.2674, AUC: 0.7915\n",
      "Epoch 00032: reducing learning rate of group 0 to 1.2500e-05.\n",
      "epoch: 32, train_loss: 0.0520, val_loss: 1.5089, AUC: 0.7965\n",
      "epoch: 33, train_loss: 0.0367, val_loss: 1.7992, AUC: 0.7963\n",
      "epoch: 34, train_loss: 0.0399, val_loss: 1.7098, AUC: 0.7960\n",
      "epoch: 35, train_loss: 0.0394, val_loss: 1.6327, AUC: 0.7971\n",
      "epoch: 36, train_loss: 0.0346, val_loss: 1.7634, AUC: 0.8021\n",
      "epoch: 37, train_loss: 0.0369, val_loss: 1.6449, AUC: 0.7940\n",
      "Epoch 00038: reducing learning rate of group 0 to 6.2500e-06.\n",
      "epoch: 38, train_loss: 0.0271, val_loss: 1.8167, AUC: 0.7975\n",
      "epoch: 39, train_loss: 0.0212, val_loss: 2.0175, AUC: 0.7963\n",
      "epoch: 40, train_loss: 0.0212, val_loss: 2.1669, AUC: 0.7948\n",
      "epoch: 41, train_loss: 0.0232, val_loss: 2.1863, AUC: 0.7952\n",
      "epoch: 42, train_loss: 0.0210, val_loss: 2.2224, AUC: 0.7993\n",
      "epoch: 43, train_loss: 0.0214, val_loss: 2.2077, AUC: 0.7975\n",
      "Epoch 00044: reducing learning rate of group 0 to 3.1250e-06.\n",
      "epoch: 44, train_loss: 0.0152, val_loss: 2.3482, AUC: 0.7963\n",
      "epoch: 45, train_loss: 0.0134, val_loss: 2.5062, AUC: 0.7947\n",
      "epoch: 46, train_loss: 0.0131, val_loss: 2.6220, AUC: 0.7963\n",
      "epoch: 47, train_loss: 0.0133, val_loss: 2.7414, AUC: 0.7942\n",
      "epoch: 48, train_loss: 0.0139, val_loss: 2.8214, AUC: 0.7953\n",
      "epoch: 49, train_loss: 0.0130, val_loss: 2.9049, AUC: 0.7936\n",
      "Epoch 00050: reducing learning rate of group 0 to 1.5625e-06.\n",
      "Best AUC for fold 2: 0.8022\n",
      "\n",
      "kf: 3\n",
      "\n",
      "epoch: 0, train_loss: 1.1025, val_loss: 0.7105, AUC: 0.5529\n",
      "New best model found with AUC: 0.5529. Model saved to best_model_fold3.pth\n",
      "epoch: 1, train_loss: 0.7027, val_loss: 0.6953, AUC: 0.5679\n",
      "New best model found with AUC: 0.5679. Model saved to best_model_fold3.pth\n",
      "epoch: 2, train_loss: 0.6890, val_loss: 0.6969, AUC: 0.6299\n",
      "New best model found with AUC: 0.6299. Model saved to best_model_fold3.pth\n",
      "epoch: 3, train_loss: 0.6731, val_loss: 0.6615, AUC: 0.6553\n",
      "New best model found with AUC: 0.6553. Model saved to best_model_fold3.pth\n",
      "epoch: 4, train_loss: 0.6512, val_loss: 0.6499, AUC: 0.6689\n",
      "New best model found with AUC: 0.6689. Model saved to best_model_fold3.pth\n",
      "epoch: 5, train_loss: 0.6340, val_loss: 0.6461, AUC: 0.6762\n",
      "New best model found with AUC: 0.6762. Model saved to best_model_fold3.pth\n",
      "epoch: 6, train_loss: 0.6161, val_loss: 0.6278, AUC: 0.7021\n",
      "New best model found with AUC: 0.7021. Model saved to best_model_fold3.pth\n",
      "epoch: 7, train_loss: 0.5992, val_loss: 0.6191, AUC: 0.7251\n",
      "New best model found with AUC: 0.7251. Model saved to best_model_fold3.pth\n",
      "epoch: 8, train_loss: 0.5979, val_loss: 0.6234, AUC: 0.7278\n",
      "New best model found with AUC: 0.7278. Model saved to best_model_fold3.pth\n",
      "epoch: 9, train_loss: 0.5552, val_loss: 0.6189, AUC: 0.7217\n",
      "epoch: 10, train_loss: 0.5408, val_loss: 0.5863, AUC: 0.7739\n",
      "New best model found with AUC: 0.7739. Model saved to best_model_fold3.pth\n",
      "epoch: 11, train_loss: 0.4963, val_loss: 0.5724, AUC: 0.7934\n",
      "New best model found with AUC: 0.7934. Model saved to best_model_fold3.pth\n",
      "epoch: 12, train_loss: 0.4649, val_loss: 0.5712, AUC: 0.7997\n",
      "New best model found with AUC: 0.7997. Model saved to best_model_fold3.pth\n",
      "epoch: 13, train_loss: 0.4161, val_loss: 0.6126, AUC: 0.8086\n",
      "New best model found with AUC: 0.8086. Model saved to best_model_fold3.pth\n",
      "epoch: 14, train_loss: 0.3735, val_loss: 0.8946, AUC: 0.7891\n",
      "epoch: 15, train_loss: 0.3569, val_loss: 0.8095, AUC: 0.8021\n",
      "epoch: 16, train_loss: 0.3142, val_loss: 0.6675, AUC: 0.8181\n",
      "New best model found with AUC: 0.8181. Model saved to best_model_fold3.pth\n",
      "epoch: 17, train_loss: 0.2760, val_loss: 0.9061, AUC: 0.7976\n",
      "epoch: 18, train_loss: 0.2624, val_loss: 0.8749, AUC: 0.8050\n",
      "Epoch 00019: reducing learning rate of group 0 to 5.0000e-05.\n",
      "epoch: 19, train_loss: 0.1700, val_loss: 1.0060, AUC: 0.8106\n",
      "epoch: 20, train_loss: 0.1330, val_loss: 0.8808, AUC: 0.8280\n",
      "New best model found with AUC: 0.8280. Model saved to best_model_fold3.pth\n",
      "epoch: 21, train_loss: 0.1318, val_loss: 0.9384, AUC: 0.8179\n",
      "epoch: 22, train_loss: 0.1095, val_loss: 1.3070, AUC: 0.7993\n",
      "epoch: 23, train_loss: 0.1195, val_loss: 1.0318, AUC: 0.8243\n",
      "epoch: 24, train_loss: 0.1044, val_loss: 1.2512, AUC: 0.8103\n",
      "Epoch 00025: reducing learning rate of group 0 to 2.5000e-05.\n",
      "epoch: 25, train_loss: 0.0785, val_loss: 1.2343, AUC: 0.8079\n",
      "epoch: 26, train_loss: 0.0654, val_loss: 1.3615, AUC: 0.8207\n",
      "epoch: 27, train_loss: 0.0608, val_loss: 1.4157, AUC: 0.8139\n",
      "epoch: 28, train_loss: 0.0634, val_loss: 1.3070, AUC: 0.8081\n",
      "epoch: 29, train_loss: 0.0627, val_loss: 1.3186, AUC: 0.8204\n",
      "epoch: 30, train_loss: 0.0627, val_loss: 1.4403, AUC: 0.8138\n",
      "Epoch 00031: reducing learning rate of group 0 to 1.2500e-05.\n",
      "epoch: 31, train_loss: 0.0413, val_loss: 1.5598, AUC: 0.8139\n",
      "epoch: 32, train_loss: 0.0342, val_loss: 1.7052, AUC: 0.8167\n",
      "epoch: 33, train_loss: 0.0346, val_loss: 1.7398, AUC: 0.8162\n",
      "epoch: 34, train_loss: 0.0379, val_loss: 1.6398, AUC: 0.8218\n",
      "epoch: 35, train_loss: 0.0352, val_loss: 1.7457, AUC: 0.8159\n",
      "epoch: 36, train_loss: 0.0330, val_loss: 1.7636, AUC: 0.8191\n",
      "Epoch 00037: reducing learning rate of group 0 to 6.2500e-06.\n",
      "epoch: 37, train_loss: 0.0284, val_loss: 1.8585, AUC: 0.8209\n",
      "epoch: 38, train_loss: 0.0211, val_loss: 2.0884, AUC: 0.8183\n",
      "epoch: 39, train_loss: 0.0202, val_loss: 2.2564, AUC: 0.8213\n",
      "epoch: 40, train_loss: 0.0224, val_loss: 2.3172, AUC: 0.8209\n",
      "epoch: 41, train_loss: 0.0215, val_loss: 2.4101, AUC: 0.8185\n",
      "epoch: 42, train_loss: 0.0195, val_loss: 2.5813, AUC: 0.8199\n",
      "Epoch 00043: reducing learning rate of group 0 to 3.1250e-06.\n",
      "epoch: 43, train_loss: 0.0160, val_loss: 2.6518, AUC: 0.8207\n",
      "epoch: 44, train_loss: 0.0130, val_loss: 2.8040, AUC: 0.8202\n",
      "epoch: 45, train_loss: 0.0125, val_loss: 2.9909, AUC: 0.8199\n",
      "epoch: 46, train_loss: 0.0120, val_loss: 3.1706, AUC: 0.8191\n",
      "epoch: 47, train_loss: 0.0122, val_loss: 3.2916, AUC: 0.8198\n",
      "epoch: 48, train_loss: 0.0130, val_loss: 3.3995, AUC: 0.8206\n",
      "Epoch 00049: reducing learning rate of group 0 to 1.5625e-06.\n",
      "epoch: 49, train_loss: 0.0097, val_loss: 3.4993, AUC: 0.8203\n",
      "Best AUC for fold 3: 0.8280\n",
      "\n",
      "kf: 4\n",
      "\n",
      "epoch: 0, train_loss: 1.1323, val_loss: 0.7276, AUC: 0.5688\n",
      "New best model found with AUC: 0.5688. Model saved to best_model_fold4.pth\n",
      "epoch: 1, train_loss: 0.7038, val_loss: 0.6804, AUC: 0.5936\n",
      "New best model found with AUC: 0.5936. Model saved to best_model_fold4.pth\n",
      "epoch: 2, train_loss: 0.7079, val_loss: 0.7833, AUC: 0.6018\n",
      "New best model found with AUC: 0.6018. Model saved to best_model_fold4.pth\n",
      "epoch: 3, train_loss: 0.6645, val_loss: 0.6918, AUC: 0.6599\n",
      "New best model found with AUC: 0.6599. Model saved to best_model_fold4.pth\n",
      "epoch: 4, train_loss: 0.6494, val_loss: 0.6522, AUC: 0.6558\n",
      "epoch: 5, train_loss: 0.6424, val_loss: 0.6517, AUC: 0.6799\n",
      "New best model found with AUC: 0.6799. Model saved to best_model_fold4.pth\n",
      "epoch: 6, train_loss: 0.6320, val_loss: 0.6471, AUC: 0.6663\n",
      "epoch: 7, train_loss: 0.6149, val_loss: 0.7258, AUC: 0.6814\n",
      "New best model found with AUC: 0.6814. Model saved to best_model_fold4.pth\n",
      "epoch: 8, train_loss: 0.5981, val_loss: 0.6400, AUC: 0.7014\n",
      "New best model found with AUC: 0.7014. Model saved to best_model_fold4.pth\n",
      "epoch: 9, train_loss: 0.5740, val_loss: 0.6396, AUC: 0.7386\n",
      "New best model found with AUC: 0.7386. Model saved to best_model_fold4.pth\n",
      "epoch: 10, train_loss: 0.5489, val_loss: 0.6449, AUC: 0.7417\n",
      "New best model found with AUC: 0.7417. Model saved to best_model_fold4.pth\n",
      "epoch: 11, train_loss: 0.5194, val_loss: 0.6266, AUC: 0.7055\n",
      "epoch: 12, train_loss: 0.4983, val_loss: 0.5894, AUC: 0.7689\n",
      "New best model found with AUC: 0.7689. Model saved to best_model_fold4.pth\n",
      "epoch: 13, train_loss: 0.4577, val_loss: 0.6764, AUC: 0.7455\n",
      "epoch: 14, train_loss: 0.4344, val_loss: 0.5851, AUC: 0.7983\n",
      "New best model found with AUC: 0.7983. Model saved to best_model_fold4.pth\n",
      "epoch: 15, train_loss: 0.4035, val_loss: 0.6503, AUC: 0.7808\n",
      "epoch: 16, train_loss: 0.3446, val_loss: 0.6983, AUC: 0.7880\n",
      "epoch: 17, train_loss: 0.3235, val_loss: 0.7502, AUC: 0.7845\n",
      "epoch: 18, train_loss: 0.2792, val_loss: 0.7663, AUC: 0.8075\n",
      "New best model found with AUC: 0.8075. Model saved to best_model_fold4.pth\n",
      "epoch: 19, train_loss: 0.2486, val_loss: 0.8968, AUC: 0.7929\n",
      "epoch: 20, train_loss: 0.2324, val_loss: 0.8248, AUC: 0.7903\n",
      "Epoch 00021: reducing learning rate of group 0 to 5.0000e-05.\n",
      "epoch: 21, train_loss: 0.1421, val_loss: 1.0213, AUC: 0.8016\n",
      "epoch: 22, train_loss: 0.1316, val_loss: 0.9685, AUC: 0.8049\n",
      "epoch: 23, train_loss: 0.1037, val_loss: 1.0056, AUC: 0.8053\n",
      "epoch: 24, train_loss: 0.1000, val_loss: 1.1810, AUC: 0.8015\n",
      "epoch: 25, train_loss: 0.1032, val_loss: 1.0122, AUC: 0.7966\n",
      "epoch: 26, train_loss: 0.0937, val_loss: 1.2197, AUC: 0.7851\n",
      "Epoch 00027: reducing learning rate of group 0 to 2.5000e-05.\n",
      "epoch: 27, train_loss: 0.0721, val_loss: 1.2907, AUC: 0.8023\n",
      "epoch: 28, train_loss: 0.0575, val_loss: 1.2242, AUC: 0.7982\n",
      "epoch: 29, train_loss: 0.0535, val_loss: 1.2382, AUC: 0.8023\n",
      "epoch: 30, train_loss: 0.0500, val_loss: 1.3549, AUC: 0.7996\n",
      "epoch: 31, train_loss: 0.0563, val_loss: 1.1980, AUC: 0.8031\n",
      "epoch: 32, train_loss: 0.0540, val_loss: 1.2992, AUC: 0.8005\n",
      "Epoch 00033: reducing learning rate of group 0 to 1.2500e-05.\n",
      "epoch: 33, train_loss: 0.0395, val_loss: 1.4538, AUC: 0.7991\n",
      "epoch: 34, train_loss: 0.0314, val_loss: 1.6269, AUC: 0.7975\n",
      "epoch: 35, train_loss: 0.0315, val_loss: 1.5944, AUC: 0.7979\n",
      "epoch: 36, train_loss: 0.0347, val_loss: 1.5946, AUC: 0.7986\n",
      "epoch: 37, train_loss: 0.0303, val_loss: 1.7110, AUC: 0.7955\n",
      "epoch: 38, train_loss: 0.0311, val_loss: 1.6430, AUC: 0.7967\n",
      "Epoch 00039: reducing learning rate of group 0 to 6.2500e-06.\n",
      "epoch: 39, train_loss: 0.0225, val_loss: 1.7776, AUC: 0.7955\n",
      "epoch: 40, train_loss: 0.0192, val_loss: 1.9719, AUC: 0.7964\n",
      "epoch: 41, train_loss: 0.0188, val_loss: 2.1551, AUC: 0.7955\n",
      "epoch: 42, train_loss: 0.0182, val_loss: 2.2792, AUC: 0.7956\n",
      "epoch: 43, train_loss: 0.0202, val_loss: 2.2975, AUC: 0.7961\n",
      "epoch: 44, train_loss: 0.0176, val_loss: 2.3568, AUC: 0.7945\n",
      "Epoch 00045: reducing learning rate of group 0 to 3.1250e-06.\n",
      "epoch: 45, train_loss: 0.0143, val_loss: 2.4705, AUC: 0.7945\n",
      "epoch: 46, train_loss: 0.0129, val_loss: 2.6079, AUC: 0.7957\n",
      "epoch: 47, train_loss: 0.0128, val_loss: 2.7550, AUC: 0.7957\n",
      "epoch: 48, train_loss: 0.0121, val_loss: 2.8840, AUC: 0.7962\n",
      "epoch: 49, train_loss: 0.0120, val_loss: 3.0175, AUC: 0.7962\n",
      "Best AUC for fold 4: 0.8075\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import time\n",
    "# 训练与测试函数\n",
    "def train_and_test(model_class, raw_train_loader, test_loader, device, num_epochs, lr, fold_count=5):\n",
    "    for kf in range(fold_count):\n",
    "        print(f\"kf: {kf}\\n\")\n",
    "        \n",
    "        # 初始化模型、损失函数、优化器和学习率调度器\n",
    "        model = model_class(1284, 1).to(device)\n",
    "        model.apply(weights_init)\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
    "\n",
    "        best_auc = 0.0  # 记录最佳AUC分数\n",
    "        best_model_path = f'best_model_fold{kf}.pth'  # 保存最佳模型路径\n",
    "\n",
    "        for epoch in range(num_epochs): \n",
    "            start = time.time() \n",
    "            model.train()\n",
    "            total_loss = 0\n",
    "            y_trues, y_preds = [], []\n",
    "\n",
    "            # 训练集\n",
    "            for data1, data2, label in raw_train_loader:\n",
    "                data1 = [d1.to(device) for d1 in data1]\n",
    "                data2 = [d2.to(device) for d2 in data2]\n",
    "                out = torch.stack([model(data1[i], data2[i]) for i in range(len(data1))])\n",
    "                loss = criterion(out, label)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                y_trues.extend(label.to('cpu').tolist())  # 将真实标签添加至列表\n",
    "                y_preds.extend(out.to('cpu').detach().numpy().flatten())  # 将预测结果展平后添加至列表\n",
    "                total_loss += loss.item()\n",
    "\n",
    "            train_loss = total_loss / len(raw_train_loader)\n",
    "\n",
    "            # 验证集\n",
    "            model.eval()\n",
    "            total_loss = 0\n",
    "            y_trues, y_preds = [], []\n",
    "            with torch.no_grad():\n",
    "                for data1, data2, label in test_loader:\n",
    "                    data1 = [d1.to(device) for d1 in data1]\n",
    "                    data2 = [d2.to(device) for d2 in data2]\n",
    "                    out = torch.stack([model(data1[i], data2[i]) for i in range(len(data1))])\n",
    "                    loss = criterion(out, label)\n",
    "                    \n",
    "                    y_trues.extend(label.to('cpu').tolist())  # 将真实标签添加至列表\n",
    "                    y_preds.extend(out.to('cpu').detach().numpy().flatten())  # 将预测结果展平后添加至列表\n",
    "                    total_loss += loss.item()\n",
    "\n",
    "            val_loss = total_loss / len(test_loader)\n",
    "\n",
    "            # 计算AUC分数\n",
    "            auc = roc_auc_score(y_trues, y_preds)\n",
    "            print(f\"epoch: {epoch}, train_loss: {train_loss:.4f}, val_loss: {val_loss:.4f}, AUC: {auc:.4f}\")\n",
    "\n",
    "            # 检查当前模型是否为最佳模型，保存最佳模型\n",
    "            if auc > best_auc:\n",
    "                best_auc = auc\n",
    "                torch.save(model.state_dict(), best_model_path)\n",
    "                print(f\"New best model found with AUC: {best_auc:.4f}. Model saved to {best_model_path}\")\n",
    "\n",
    "            scheduler.step(val_loss)\n",
    "\n",
    "        print(f\"Best AUC for fold {kf}: {best_auc:.4f}\\n\")\n",
    "\n",
    "\n",
    "train_and_test(GCN, raw_train_loader, test_loader, device, num_epochs=50, lr=0.0001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP\tTN\tFP\tFN\tprecision\trecall\tspecificity\tAcc\tMCC\tf1\tAUROC\tAUPRC\n",
      "118\t117\t34\t31\t0.7763\t0.792\t0.775\t0.783\t0.567\t0.784\t0.836\t0.824\n",
      "[[0.00000196]\n",
      " [0.02064813]\n",
      " [0.99800771]\n",
      " ...\n",
      " [0.12655888]\n",
      " [0.998743  ]\n",
      " [0.98010921]]\n",
      "TP\tTN\tFP\tFN\tprecision\trecall\tspecificity\tAcc\tMCC\tf1\tAUROC\tAUPRC\n",
      "288\t311\t288\t313\t0.5\t0.479\t0.519\t0.499\t-0.002\t0.489\t0.496\t0.492\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn import metrics\n",
    "from zzd.utils.assess import multi_scores as scores\n",
    "# 加载模型\n",
    "try:\n",
    "    model_path = '/mnt/disk1/guoxiaokun/isoform/double.GCN/second.result.e25.p01.filteradj.fold2_best_model.pth'\n",
    "    model = GCN(1284, 1).to(device)  # 1284 是输入特征维度，1 是输出维度\n",
    "    model.load_state_dict(torch.load(model_path))  \n",
    "    model.eval()  \n",
    "    \n",
    "     # 进行测试数据的预测\n",
    "    model.eval()         \n",
    "    with torch.no_grad():\n",
    "        y_tures = []\n",
    "        y_preds = []\n",
    "        for data1, data2, label in test_loader:\n",
    "            data1 = [d1.to(device) for d1 in data1]\n",
    "            data2 = [d2.to(device) for d2 in data2]\n",
    "            out = []\n",
    "            for i in range(len(data1)):\n",
    "                o = model(data1[i],data2[i])\n",
    "                out.append(o)\n",
    "            # print(f\"data1:{data1},data2:{data2}\")\n",
    "            out = torch.stack(out)\n",
    "            out = torch.sigmoid(out)\n",
    "            y_preds.append(out.to('cpu').detach().tolist())\n",
    "            y_tures.append(label.to('cpu').tolist())\n",
    "        # scores(np.array(y_trues),np.array(y_preds),show=True)\n",
    "        y_preds = [item for sublist in y_preds for item in sublist]\n",
    "        y_pred = np.array(y_preds)\n",
    "        # print(y_pred)\n",
    "        pred_table = np.hstack(( np.genfromtxt(test_file,str),y_pred.reshape(-1,1)))\n",
    "        # print(f\"pred_table:{pred_table}\")\n",
    "        result_score = scores(pred_table[:,-2], pred_table[:,-1],show=True)  \n",
    "    # 将预测分数和真实标签输出到文件\n",
    "    with open(\"GCN.ESM2.test.predict.txt\", \"w\") as f:\n",
    "\n",
    "        for i in range(len(pred_table)):\n",
    "            f.write(f\"{pred_table[i, 0]}\\t{pred_table[i, 1]}\\t{pred_table[i, -2]}\\t{pred_table[i, -1]}\\n\")\n",
    "\n",
    "    # model.eval()         \n",
    "    with torch.no_grad():\n",
    "        y_tures = []\n",
    "        y_preds = []\n",
    "        for data1, data2, label in raw_train_loader:\n",
    "            data1 = [d1.to(device) for d1 in data1]\n",
    "            data2 = [d2.to(device) for d2 in data2]\n",
    "            # label = [d3.to(device) for d3 in labels]\n",
    "            out = []\n",
    "            for i in range(len(data1)):\n",
    "                o = model(data1[i],data2[i])\n",
    "                out.append(o)\n",
    "            # print(f\"data1:{data1},data2:{data2}\")\n",
    "            out = torch.stack(out)\n",
    "            out = torch.sigmoid(out)\n",
    "            y_preds.append(out.to('cpu').detach().tolist())\n",
    "            y_tures.append(label.to('cpu').tolist())\n",
    "        # scores(np.array(y_trues),np.array(y_preds),show=True)\n",
    "        y_preds = [item for sublist in y_preds for item in sublist]\n",
    "        y_pred = np.array(y_preds)\n",
    "        print(y_pred)\n",
    "        pred_table = np.hstack(( np.genfromtxt(train_file,str),y_pred.reshape(-1,1)))\n",
    "        # print(f\"pred_table:{pred_table}\")\n",
    "        result_score = scores(pred_table[:,-2], pred_table[:,-1],show=True)\n",
    "    # 将预测分数和真实标签输出到文件\n",
    "    with open(\"GCN.ESM2.train.predict.txt\", \"w\") as f:\n",
    "        for i in range(len(pred_table)):\n",
    "            f.write(f\"{pred_table[i, 0]}\\t{pred_table[i, 1]}\\t{pred_table[i, -2]}\\t{pred_table[i, -1]}\\n\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"模型加载或预测时出现错误：\", str(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn import metrics\n",
    "import random\n",
    "import pandas as pd\n",
    "import scipy.sparse as spp\n",
    "from zzd.utils.assess import multi_scores as scores\n",
    "class ProteinDataLoader:\n",
    "    def __init__(self, protein_dict, train_file, test_file, batch_size=3, seed=2066):\n",
    "        self.device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "        self.protein_dict = protein_dict\n",
    "        self.batch_size = batch_size\n",
    "        self.seed = seed\n",
    "        self.setup_seed(self.seed)\n",
    "        \n",
    "        # Load train and test data\n",
    "        self.train_file = train_file\n",
    "        self.test_file = test_file\n",
    "        self.train_df = pd.read_csv(self.train_file, sep=\"\\t\", header=None)\n",
    "        self.test_df = pd.read_csv(self.test_file, sep=\"\\t\", header=None)\n",
    "        \n",
    "        # Prepare datasets and dataloaders no shuffle\n",
    "        self.test_data = self.generate_data(self.test_df)\n",
    "        self.test_dataset = ProteinDataset(self.test_data)\n",
    "        self.test_loader = DataLoader(self.test_dataset, batch_size=self.batch_size, shuffle=False, collate_fn=self.collate_fn)\n",
    "\n",
    "        self.raw_train_data = self.generate_data(self.train_df)\n",
    "        self.raw_train_dataset = ProteinDataset(self.raw_train_data)\n",
    "        self.raw_train_loader = DataLoader(self.raw_train_dataset, batch_size=self.batch_size, shuffle=False, collate_fn=self.collate_fn)\n",
    "    \n",
    "    def setup_seed(self, seed):\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "    def generate_data(self, df):\n",
    "        \"\"\"Generate data list from dataframe and protein dictionary.\"\"\"\n",
    "        data_list = []\n",
    "        for i in range(len(df)):\n",
    "            protein1, protein2, label = df.iloc[i]\n",
    "            data1 = self.protein_dict[protein1]\n",
    "            data2 = self.protein_dict[protein2]\n",
    "            data_list.append((data1, data2, torch.tensor([label], dtype=torch.float).to(self.device)))\n",
    "        return data_list\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        \"\"\"Custom collate function for DataLoader.\"\"\"\n",
    "        data1 = [item[0] for item in batch]\n",
    "        data2 = [item[1] for item in batch]\n",
    "        label = torch.stack([item[2] for item in batch])\n",
    "        return [data1, data2, label]\n",
    "\n",
    "class ProteinDataset(Dataset):\n",
    "    \"\"\"Custom Dataset class for protein interaction data.\"\"\"\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "       \n",
    "train_file = 'train.txt'\n",
    "test_file = 'test.txt'\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "data_loader = ProteinDataLoader(protein_dict, train_file, test_file)\n",
    "# Access the dataloaders\n",
    "test_loader = data_loader.test_loader\n",
    "raw_train_loader = data_loader.raw_train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP\tTN\tFP\tFN\tprecision\trecall\tspecificity\tAcc\tMCC\tf1\tAUROC\tAUPRC\n",
      "118\t117\t34\t31\t0.7763\t0.792\t0.775\t0.783\t0.567\t0.784\t0.836\t0.824\n",
      "Scores for test: (118, 117, 34, 31, 0.7763, 0.7919, 0.7748, 0.78333, 0.56682, 0.78405, 0.83644, 0.82429)\n",
      "TP\tTN\tFP\tFN\tprecision\trecall\tspecificity\tAcc\tMCC\tf1\tAUROC\tAUPRC\n",
      "564\t587\t12\t37\t0.9792\t0.938\t0.980\t0.959\t0.919\t0.958\t0.994\t0.995\n",
      "Scores for train: (564, 587, 12, 37, 0.9792, 0.9384, 0.98, 0.95917, 0.91914, 0.95837, 0.99409, 0.99458)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def setup_model_and_predict(model_class, model_path, device, test_loader, train_loader, test_file, train_file, output_test_file, output_train_file):\n",
    "    \"\"\"\n",
    "    Function to load a model, perform predictions on test and train data, and save the results to files.\n",
    "\n",
    "    Parameters:\n",
    "    - model_class: The model class (e.g., GCN).\n",
    "    - model_path: The path to the trained model file (.pth).\n",
    "    - device: The device to run the model on (e.g., 'cuda' or 'cpu').\n",
    "    - test_loader: DataLoader for test data.\n",
    "    - train_loader: DataLoader for train data.\n",
    "    - test_file: File containing test data information.\n",
    "    - train_file: File containing train data information.\n",
    "    - output_test_file: File path to save test prediction results.\n",
    "    - output_train_file: File path to save train prediction results.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the model\n",
    "        model = model_class(1284, 1).to(device)  # 1284 is the input feature dimension, 1 is the output dimension\n",
    "        model.load_state_dict(torch.load(model_path)) \n",
    "        model.eval() \n",
    "        \n",
    "        def predict_and_save(loader, input_file, output_file, phase):\n",
    "            y_trues, y_preds = [], []\n",
    "            with torch.no_grad():\n",
    "                for data1, data2, label in loader:\n",
    "                    data1 = [d1.to(device) for d1 in data1]\n",
    "                    data2 = [d2.to(device) for d2 in data2]\n",
    "                    out = []\n",
    "                    for i in range(len(data1)):\n",
    "                        o = model(data1[i], data2[i])\n",
    "                        out.append(o)\n",
    "                    out = torch.stack(out)\n",
    "                    out = torch.sigmoid(out)\n",
    "                    y_preds.append(out.to('cpu').detach().tolist())\n",
    "                    y_trues.append(label.to('cpu').tolist())\n",
    "                \n",
    "            y_preds = [item for sublist in y_preds for item in sublist]\n",
    "            y_pred = np.array(y_preds)\n",
    "            pred_table = np.hstack((np.genfromtxt(input_file, str), y_pred.reshape(-1, 1)))\n",
    "            result_score = scores(pred_table[:, -2], pred_table[:, -1], show=True)\n",
    "            print(f\"Scores for {phase}: {result_score}\")\n",
    "\n",
    "            with open(output_file, \"w\") as f:\n",
    "                for i in range(len(pred_table)):\n",
    "                    f.write(f\"{pred_table[i, 0]}\\t{pred_table[i, 1]}\\t{pred_table[i, -2]}\\t{pred_table[i, -1]}\\n\")\n",
    "        \n",
    "        predict_and_save(test_loader, test_file, output_test_file, \"test\")\n",
    "        predict_and_save(train_loader, train_file, output_train_file, \"train\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error occurred during model loading or prediction:\", str(e))\n",
    "\n",
    "\n",
    "setup_model_and_predict(GCN, \"/mnt/disk1/guoxiaokun/isoform/double.GCN/second.result.e25.p01.filteradj.fold2_best_model.pth\", device, test_loader, raw_train_loader, test_file, train_file, \"GCN.ESM2.test.predict.txt\", \"GCN.ESM2.train.predict.txt\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch2.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
